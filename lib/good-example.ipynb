{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1675, 32, 489])\n",
      "torch.Size([1, 32, 489])\n",
      "[[-3.212835   3.2312775 -2.4132507]]\n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4b995d750>, {'not changed .': 2, 'not changed ,': 1, 'added .': 1, 'possible punctuation places': 7})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb7026e30524923855e3003a251b492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function task.<locals>.<lambda> at 0x7fa4b995dab0>, {'added .': 58, 'added ,': 251, 'not changed .': 327, 'removed .': 5, 'not changed ,': 880, 'changed , with .': 4, 'removed ,': 35, 'possible punctuation places': 9204})\n"
     ]
    }
   ],
   "source": [
    "import xformers\n",
    "import torch\n",
    "# print(torch.ops.xformers.matmul_with_mask(torch.Tensor([[1, 2], [3, 4]]),\n",
    "#                                         torch.Tensor([[1, 2], [3,4]]),\n",
    "#                                         torch.Tensor([[True, False], [False, False]])))\n",
    "\n",
    "# res = torch.matmul(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 2], [3,4]]))\n",
    "# res[torch.Tensor([[True, False], [False, False]]).bool().logical_not()] =-float(\"Inf\")\n",
    "# print(res)\n",
    "# exit(0)\n",
    "\n",
    "import dill\n",
    "import torch\n",
    "from storage import Storage\n",
    "prefix = \"results_big_model_GOOD_2022-05-15\"\n",
    "# print(\"ADD RESULTS \")\n",
    "# with open(f\"{prefix}/some_model_CLASS.dill\", \"rb\") as file:\n",
    "#     Model = dill.load(file)\n",
    "# model = torch.load(f\"{prefix}/some_model.pt\", map_location=torch.device('cpu')) #).v1\", map_location=torch.device('cuda:0'))\n",
    "\n",
    "with open(f\"{prefix}/storage_path.dill\", \"rb\") as file:\n",
    "    storage_path = dill.load(file)\n",
    "\n",
    "\n",
    "storage = Storage(str(storage_path))\n",
    "params = storage.get_meta(\"params\")\n",
    "x_test = storage.get(\"x\", 0).float()\n",
    "print(x_test.shape)\n",
    "\n",
    "dummy_input = x_test[0:1]\n",
    "print(dummy_input.shape)\n",
    "\n",
    "\n",
    "\n",
    "# from xformers.components.attention.attention_patterns import (\n",
    "#     local_1d_pattern)\n",
    "# for i in [3, 4, 5, 6, 7]:\n",
    "#     att = list(model.children())[0][i].wrap_att.layer.sublayer.children().__next__()\n",
    "#     # att._get_local_mask = lambda shape: local_1d_pattern(shape[1], att.window_size * 3).to_sparse()\n",
    "#     att.attention_mask = None\n",
    "\n",
    "# # torch.jit.script(model, example_inputs=[(dummy_input, )])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     print(model(dummy_input))\n",
    "#     torch.onnx.export(model, (dummy_input, ), f\"{prefix}/model.onnx\",\n",
    "#                     input_names = ['input'],\n",
    "#                     output_names = ['output'],\n",
    "#                       #verbose=True\n",
    "#                       )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pymorphy3\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from razdel import tokenize\n",
    "\n",
    "from dataset_builder import calculate_word_features_for_tokens, PAD_TOKEN,get_word_features\n",
    "from inference import torch_model_runner, onnx_model_runner, infer\n",
    "\n",
    "# print(\"PREFIX\\n\" * 100)\n",
    "\n",
    "# onnx_model = onnx_model_runner(\"results writers big/model.onnx\")\n",
    "onnx_model = onnx_model_runner(f\"{prefix}/model.onnx\")\n",
    "with open(\"params.pickle\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "print(onnx_model(dummy_input.numpy()))\n",
    "\n",
    "class jsinfer:\n",
    "    async def infer(arr):\n",
    "        class wrapper:\n",
    "            def to_py():\n",
    "                return onnx_model(arr)\n",
    "        return wrapper\n",
    "\n",
    "from stream import Stream\n",
    "import functools\n",
    "from collections import deque\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "@functools.lru_cache(maxsize=128)\n",
    "def get_word_features_cached(word):\n",
    "    return get_word_features(word, params).numpy()\n",
    "\n",
    "class Substr:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Substring(-1, -1, {self.text})\"\n",
    "\n",
    "def d_as_str(d):\n",
    "  return \"<\" + \" \".join(map(lambda text: text.text, d))+ \">\"\n",
    "\n",
    "async def infer_optimal(params, text):\n",
    "  # print(\"INFERCENC IS WIERD\\n\" * 10)\n",
    "  res = []\n",
    "  last_inserted_pos = 0\n",
    "  def sink(token, log=False):\n",
    "    nonlocal last_inserted_pos\n",
    "    if token.text == \"PAD\": return\n",
    "    if log: print('sink', token)\n",
    "    if isinstance(token, Substr):\n",
    "      res.append(token.text)\n",
    "      if log: print(\"added1 \", f\"`{token.text}`\", token)\n",
    "    else:\n",
    "      if last_inserted_pos != token.start:\n",
    "        res.append(text[last_inserted_pos: token.start])\n",
    "        if log: print(\"added2 \", f\"`{text[last_inserted_pos: token.start]}`\", last_inserted_pos, token.start)\n",
    "      last_inserted_pos = token.stop\n",
    "      res.append(token.text)\n",
    "      if log: print(\"added3 \", f\"`{token.text}`\", token)\n",
    "\n",
    "  def skip(token, log=False):\n",
    "    nonlocal last_inserted_pos\n",
    "    last_inserted_pos = token.stop\n",
    "    if log: print('skip', token)\n",
    "\n",
    "  def sink_remaining():\n",
    "     res.append(text[last_inserted_pos:])\n",
    "\n",
    "\n",
    "  async def predict_on_tokens(window_left, window_right, return_probas):\n",
    "    features = [get_word_features_cached(i.text) for i in Stream(window_left).chain(window_right)]\n",
    "    features_for_batch = np.stack((features, ))\n",
    "    arr = np.ascontiguousarray(features_for_batch, dtype=np.float32)\n",
    "    output_probas = np.array((await jsinfer.infer(arr)).to_py())\n",
    "    # output_probas[0][0] += 2.\n",
    "    if return_probas:\n",
    "      return params[\"ID_TO_PUNCTUATION\"], output_probas\n",
    "    punct_idx = np.argmax(output_probas).item()\n",
    "    punct = params[\"ID_TO_PUNCTUATION\"][punct_idx]\n",
    "    return punct\n",
    "\n",
    "\n",
    "  window_left = deque()\n",
    "  window_right = deque()\n",
    "  log = False\n",
    "  skip_next = False\n",
    "  for i in Stream.repeat(Substr(PAD_TOKEN), params['INPUT_WORDS_CNT_LEFT']) \\\n",
    "      .chain(Stream(tokenize(text))) \\\n",
    "      .chain(Stream.repeat(Substr(PAD_TOKEN), params[\"INPUT_WORDS_CNT_RIGHT\"])):\n",
    "    window_right.append(i)\n",
    "    if len(window_right) <= params[\"INPUT_WORDS_CNT_RIGHT\"]:\n",
    "        continue\n",
    "    assert len(window_right) == params[\"INPUT_WORDS_CNT_RIGHT\"] + 1\n",
    "\n",
    "    next_ = window_right.popleft()\n",
    "    sink(next_)\n",
    "    window_left.append(next_)\n",
    "    if len(window_left) < params['INPUT_WORDS_CNT_LEFT']:\n",
    "      continue\n",
    "\n",
    "    assert len(window_left) == params[\"INPUT_WORDS_CNT_LEFT\"]\n",
    "    assert len(window_right) == params[\"INPUT_WORDS_CNT_RIGHT\"]\n",
    "\n",
    "    if skip_next:\n",
    "      prediction = \"$skip\"\n",
    "    else:\n",
    "      # params[\"ID_TO_PUNCTUATION\"], output_probas\n",
    "      prediction = await predict_on_tokens(window_left, window_right, return_probas=False)\n",
    "\n",
    "\n",
    "    #random.choice([\" \", \".\"])\n",
    "    if log: print(d_as_str(window_left).rjust(100), prediction.center(6), d_as_str(window_right))\n",
    "\n",
    "    def is_replaceable_punct(punct):\n",
    "      return punct in ',.'\n",
    "\n",
    "    if prediction == \"$skip\":\n",
    "      pass\n",
    "    elif prediction != \"$empty\":\n",
    "      if is_replaceable_punct(window_right[0].text):\n",
    "        if window_right[0].text != prediction:\n",
    "          window_right[0].text = prediction\n",
    "      else:\n",
    "        window_left.append(Substr(prediction))\n",
    "        sink(window_left[-1])\n",
    "    else:\n",
    "      if is_replaceable_punct(window_right[0].text):\n",
    "          skip(window_right.popleft())\n",
    "\n",
    "    skip_next = is_replaceable_punct(window_right[0].text)\n",
    "\n",
    "    while len(window_left) != params['INPUT_WORDS_CNT_LEFT'] - 1:\n",
    "      token = window_left.popleft()\n",
    "\n",
    "    if log: print(d_as_str(window_left).rjust(100), \"      \", d_as_str(window_right))\n",
    "\n",
    "  for i in window_right:\n",
    "    sink(i)\n",
    "  sink_remaining()\n",
    "  ress = \"\".join(res)\n",
    "  return ress\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "text = \"Тест. тест, тест. Тест\"\n",
    "text_res = \"Тест. тест, тест. Тест.\"\n",
    "# text_res = await infer_optimal(params, text)\n",
    "\n",
    "def calculate_diff2(text, text_res):\n",
    "  res = defaultdict(lambda: 0)\n",
    "\n",
    "  def is_punctuation(c):\n",
    "      return c in \".,\"\n",
    "\n",
    "  def sink_add(c):\n",
    "    nonlocal res\n",
    "    res['added ' + c] += 1\n",
    "\n",
    "  def sink_remove(c):\n",
    "    nonlocal res\n",
    "    res['removed ' + c] += 1\n",
    "\n",
    "  def sink_change(c1, c2):\n",
    "    nonlocal res\n",
    "    res['changed ' + c1 + \" with \" + c2] += 1\n",
    "\n",
    "  i = 0\n",
    "  j = 0\n",
    "  while True:\n",
    "      if i >= len(text): break\n",
    "      if j >= len(text_res): break\n",
    "      # print(text[i], text_res[j])\n",
    "      if text[i] == text_res[j]:\n",
    "          if is_punctuation(text[i]):\n",
    "             res['not changed ' + text[i]] += 1\n",
    "          i += 1\n",
    "          j += 1\n",
    "          continue\n",
    "\n",
    "      if is_punctuation(text[i]) and is_punctuation(text_res[j]):\n",
    "        sink_change(text[i], text_res[j])\n",
    "        i += 1\n",
    "        j += 1\n",
    "        continue\n",
    "\n",
    "      if is_punctuation(text[i]):\n",
    "        sink_remove(text[i])\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "      if is_punctuation(text_res[j]):\n",
    "        sink_add(text_res[j])\n",
    "        j += 1\n",
    "        continue\n",
    "\n",
    "      raise Exception(\"Change not in punctuation\", text[i], text_res[j], \"at \", i, j)\n",
    "\n",
    "  while i < len(text):\n",
    "    # print(\"remaining: \", text[i])\n",
    "    assert is_punctuation(text[i])\n",
    "    sink_remove(text[i])\n",
    "    i += 1\n",
    "\n",
    "  while j < len(text_res):\n",
    "    # print(\"remaining(2): \",text_res[j])\n",
    "    assert is_punctuation(text_res[j])\n",
    "    sink_add(text_res[j])\n",
    "    j += 1\n",
    "\n",
    "  res['possible punctuation places'] = len(list(tokenize(text)))\n",
    "\n",
    "  return res\n",
    "\n",
    "\n",
    "\n",
    "print(calculate_diff2(text, text_res))\n",
    "# print(infer_optimal(params, \"кек\\n\"))\n",
    "\n",
    "\n",
    "import glob\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def dicts_sum(dict1, dict2):\n",
    "  for key in dict2:\n",
    "    dict1[key] += dict2[key]\n",
    "  return dict1\n",
    "\n",
    "async def task(clear_punctuation):\n",
    "    global txt, text_to_infer\n",
    "    res = defaultdict(lambda: 0)\n",
    "    i = 0\n",
    "    for rtf_path in tqdm(glob.glob(\"../validation/Mark Tven/Mark Tven rtf/*.rtf\")):\n",
    "        with open(rtf_path, \"rb\") as rtf_file:\n",
    "            encoded = rtf_file.read()\n",
    "            try:\n",
    "                rtf = encoded.decode('cp1251')\n",
    "                txt = rtf_to_text(rtf)\n",
    "                if clear_punctuation:\n",
    "                   text_to_infer = txt.replace(\". \", \" \").replace(\", \", \" \")\n",
    "                else:\n",
    "                   text_to_infer = txt\n",
    "\n",
    "                diff = calculate_diff2(txt, await infer_optimal(params, text_to_infer))\n",
    "                res = dicts_sum(res, diff)\n",
    "            except Exception as ex:\n",
    "                print(\"skipped \", rtf_path, len(encoded), ex)\n",
    "            # raise\n",
    "            i += 1\n",
    "            if i> 0: break\n",
    "\n",
    "    print(res)\n",
    "\n",
    "\n",
    "\n",
    "await task(clear_punctuation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Марк Твен \\nРазмышления о религии\\n\\nТвен Марк\\nРазмыш'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtf_path = \"../validation/Mark Tven/Mark Tven rtf/Tven_Priklyucheniya_Toma_Soyera_i_Geklberri_Finna_1_Priklyucheniya_Toma_Soyera.57094.rtf\"\n",
    "rtf_path = \"../validation/Mark Tven/Mark Tven rtf/Tven_Priklyucheniya_Toma_Soyera_i_Geklberri_Finna_1_Priklyucheniya_Toma_Soyera.103501.rtf\"\n",
    "rtf_path = \"../validation/Mark Tven/Mark Tven rtf/Tven_Razmyishleniya_o_religii.57105.rtf\"\n",
    "\n",
    "with open(rtf_path, \"rb\") as rtf_file:\n",
    "    encoded = rtf_file.read()\n",
    "    rtf = encoded.decode('cp1251', 'ignore')\n",
    "    txt = rtf_to_text(rtf, errors='ignore')#, encoding='cp1251', errors='ignore')\n",
    "txt[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\\\rtf1\\\\ansi\\\\ansicpg1251\\\\deff0\\\\deflang1049\\\\deflangfe1049\\\\deftab708{\\\\fonttbl{\\\\f0\\\\fswiss\\\\fprq2\\\\fcharset'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Марк Твен \\nПриключения Тома Сойера\\n\\nПриключения Тома Сойера – 1\\n\\n\\n\\nМарк Твен\\nПРИКЛЮЧЕНИЯ ТОМА СОЙЕРА'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хотя долгая привычка к лести и закалила наших восточных монархов, даже они не могли бы снести раздающихся по воскресеньям в церквах бесстыдных восхвалений, которые наш бог выслушивает самодовольно и удовлетворенно. \n",
      "Мы, не краснея, называем нашего бога источником милосердия, хотя отлично знаем, что во всей его истории не найдется ни одного случая, когда он на самом деле проявил бы милосердие. Мы называем его источником нравственности, хотя его история и его повседневное поведение, о котором нам свидетельствуют наши собственные чувства, неопровержимо доказывают, что он абсолютно лишен даже какоголибо подобия нравственности или морали. \n",
      "Хотя долгая привычка к лести и закалила наших восточных монархов, даже они не могли бы снести раздающихся по воскресеньям в церквах бесстыдных восхвалений, которые наш бог выслушивает самодовольно и удовлетворенно. \n",
      "Мы, не краснея, называем нашего бога источником милосердия, хотя отлично знаем, что во всей его истории не найдется ни одного случая, когда он на самом деле проявил бы милосердие. Мы называем его источником нравственности, хотя его история и его повседневное поведение, о котором нам свидетельствуют наши собственные чувства, неопровержимо доказывают, что он абсолютно лишен даже какоголибо подобия нравственности или морали. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08c550>, {'not changed ,': 11, 'not changed .': 3, 'possible punctuation places': 104, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Он не делает вида, будто обладает какойнибудь моралью или какиминибудь добродетелями, разве что на словах. В его поведении невозможно найти и следа чеголибо подобного. На мой взгляд, он несравненно ближе к тому, чтобы быть достойным уважения, чем его исправившееся \"я\", столь бесхитростно разоблачаемое в Новом завете. \n",
      "Он не делает вида, будто обладает какойнибудь моралью или какиминибудь добродетелями, разве что на словах. В его поведении невозможно найти и следа чеголибо подобного. На мой взгляд он несравненно ближе к тому, чтобы быть достойным уважения, чем его исправившееся \"я\", столь бесхитростно разоблачаемое в Новом завете. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08e290>, {'not changed ,': 5, 'not changed .': 3, 'removed ,': 1, 'possible punctuation places': 57, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0})\n",
      "False\n",
      "===\n",
      "Буддисты были ужасно счастливы, когда 2500 лет тому назад они с помощью того же процесса обзавелись Гаутамой. Греки в те же времена чрезвычайно высоко его ценили, потому что их верховное божество и его\n",
      "приближенные завели обыкновение спускаться с горных вершин и населять Грецию ублюдкамиполулюдьмиполубогами. Римляне позаимствовали у Греции эту идею, и плоды, которыми с помощью Непорочного Зачатия снабжал их Юпитер, доставляли им великую радость. \n",
      "Буддисты были ужасно счастливы, когда 2500 лет тому назад они с помощью того же процесса обзавелись Гаутамой. Греки в те же времена чрезвычайно высоко его ценили, потому что их верховное божество и его\n",
      "приближенные завели обыкновение спускаться с горных вершин и населять Грецию ублюдкамиполулюдьмиполубогами. Римляне позаимствовали у Греции эту идею и плоды, которыми с помощью Непорочного Зачатия снабжал их Юпитер, доставляли им великую радость. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08c550>, {'not changed ,': 4, 'not changed .': 3, 'removed ,': 1, 'possible punctuation places': 72, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0})\n",
      "False\n",
      "===\n",
      "Греки в те же времена чрезвычайно высоко его ценили, потому что их верховное божество и его\n",
      "приближенные завели обыкновение спускаться с горных вершин и населять Грецию ублюдкамиполулюдьмиполубогами. Римляне позаимствовали у Греции эту идею, и плоды, которыми с помощью Непорочного Зачатия снабжал их Юпитер, доставляли им великую радость. А мы получили эту идею непосредственно с Небес  через Рим. \n",
      "Греки в те же времена чрезвычайно высоко его ценили, потому что их верховное божество и его\n",
      "приближенные завели обыкновение спускаться с горных вершин и населять Грецию ублюдкамиполулюдьмиполубогами. Римляне позаимствовали у Греции эту идею и плоды, которыми с помощью Непорочного Зачатия снабжал их Юпитер, доставляли им великую радость. А мы получили эту идею непосредственно с Небес  через Рим. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08d900>, {'not changed ,': 3, 'not changed .': 3, 'removed ,': 1, 'possible punctuation places': 64, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0})\n",
      "False\n",
      "===\n",
      "Доктрина о Непорочном Зачатии целиком спирается на показания одногоединственного свидетеля, причем свидетеля, чьи показания не имеют никакой ценности, поскольку о самом его существовании мы знаем только со слов молодой крестьянки, которой нужно было утихомирить своего мужа. Свидетельство Марии его удовлетворило, но только потому, что он жил в Назарете, а не в НьюЙорке. В НьюЙорке не найдется ни одного плотника, который поверил бы подобному свидетельству. \n",
      "Доктрина о Непорочном Зачатии целиком спирается на показания одногоединственного свидетеля, причем свидетеля, чьи показания не имеют никакой ценности, поскольку о самом его существовании мы знаем только со слов молодой крестьянки, которой нужно было утихомирить своего мужа. Свидетельство Марии его удовлетворило, но только потому, что он жил в Назарете, а не в НьюЙорке. В НьюЙорке не найдется ни одного плотника, который поверил бы подобному свидетельству. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08d900>, {'not changed ,': 8, 'not changed .': 3, 'possible punctuation places': 75, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Оно вызвало бы смех, а не благоговение и поклонение. \n",
      "Тому, кто в него не верит, оно кажется просто детской сказочкой. Только бог мог вообразить, что это  нечто грандиозное и хитроумное и может внушить благоговение. \n",
      "Оно вызвало бы смех, а не благоговение и поклонение. \n",
      "Тому, кто в него не верит, оно кажется просто детской сказочкой. Только бог мог вообразить, что это  нечто грандиозное и хитроумное и может внушить благоговение. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08e290>, {'not changed ,': 4, 'not changed .': 3, 'possible punctuation places': 41, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Эти избиения происходят так часто, что мы стали к ним почти равнодушны. Рассказы о них волнуют нас не больше, чем сообщение о падении железнодорожных акций, в которые мы не вкладывали денег. Мы так привыкли к описаниям этих ужасов, что теперь, читая о них, даже не содрогаемся. \n",
      "Эти избиения происходят так часто, что мы стали к ним почти равнодушны. Рассказы о них волнуют нас не больше, чем сообщение о падении железнодорожных акций, в которые мы не вкладывали денег. Мы так привыкли к описаниям этих ужасов, что теперь, читая о них, даже не содрогаемся. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa5dfc83b50>, {'not changed ,': 6, 'not changed .': 3, 'possible punctuation places': 55, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Когда его труп был доставлен в больницу, на нем были также обнаружены следы штыковых ударов. \n",
      "Рядом с Апштейном лежал труп десятилетнего ребенка, которому топором отрубили ногу. Тут же лежали жертвы из дома Шляхтера, куда, согласно показаниям свидетелей, вломились солдаты, которые, ограбив дом, убили жену Шляхтера, его сына и дочь соседей, а ему самому и его двум дочерям нанесли тяжелые ранения. \n",
      "Когда его труп был доставлен в больницу, на нем были также обнаружены следы штыковых ударов. \n",
      "Рядом с Апштейном лежал труп десятилетнего ребенка, которому топором отрубили ногу. Тут же лежали жертвы из дома Шляхтера, куда, согласно показаниям свидетелей, вломились солдаты, которые, ограбив дом, убили жену Шляхтера, его сына и дочь соседей, а ему самому и его двум дочерям нанесли тяжелые ранения. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa5dfc83b50>, {'not changed ,': 10, 'not changed .': 3, 'possible punctuation places': 73, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Рядом с Апштейном лежал труп десятилетнего ребенка, которому топором отрубили ногу. Тут же лежали жертвы из дома Шляхтера, куда, согласно показаниям свидетелей, вломились солдаты, которые, ограбив дом, убили жену Шляхтера, его сына и дочь соседей, а ему самому и его двум дочерям нанесли тяжелые ранения. \n",
      "Мне сообщили, что солдаты ворвались в набитую людьми квартиру братьев Лапидус и приказали христианам отойти от евреев. \n",
      "Рядом с Апштейном лежал труп десятилетнего ребенка, которому топором отрубили ногу. Тут же лежали жертвы из дома Шляхтера, куда, согласно показаниям свидетелей, вломились солдаты, которые, ограбив дом, убили жену Шляхтера, его сына и дочь соседей, а ему самому и его двум дочерям нанесли тяжелые ранения. \n",
      "Мне сообщили, что солдаты ворвались в набитую людьми квартиру братьев Лапидус и приказали христианам отойти от евреев. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4b983fc70>, {'not changed ,': 10, 'not changed .': 3, 'possible punctuation places': 75, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Можно только поражаться всеобъемлющей и всепроницающей злобе, которая терпеливо снизошла до того, чтобы изобрести сложнейшие пытки для самых жалких и крохотных из бесчисленных существ, населивших землю. Паук был устроен так, что он не стал есть траву, а вынужден был ловить мух и других подобных же созданий и обрекать их на медленную, мучительную смерть, не сознавая, что скоро придет и его черед. Оса была устроена так, что она тоже отказывалась от травы и жалила паука, не даруя ему при этом быстрой и милосердной смерти, а только парализуя его, чтобы затем сунуть в осиное гнездо, где ему предстоит еще долго жить и страдать, пока осиный молодняк будет не торопясь объедать ему ноги. \n",
      "Можно только поражаться всеобъемлющей и всепроницающей злобе, которая терпеливо снизошла до того, чтобы изобрести сложнейшие пытки для самых жалких и крохотных из бесчисленных существ, населивших землю. Паук был устроен так, что он не стал есть траву, а вынужден был ловить мух и других подобных же созданий и обрекать их на медленную, мучительную смерть, не сознавая, что скоро придет и его черед. Оса была устроена так, что она тоже отказывалась от травы и жалила паука, не даруя ему при этом быстрой и милосердной смерти, а только парализуя его, чтобы затем сунуть в осиное гнездо, где ему предстоит еще долго жить и страдать, пока осиный молодняк будет не торопясь объедать ему ноги. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08c550>, {'not changed ,': 14, 'not changed .': 3, 'possible punctuation places': 127, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "И все же наказание, которое терпит муха, в десять тысяч раз более сурово, чем заслуживает подобный проступок. \n",
      "Закон десятитысячекратной кары строго соблюдается по отношению ко всем живым существам, включая и человека. Всякий долг, был ли он сделан сознательно или по незнанию, природа немедленно взыскивает еще на этом свете, не откладывая сведения счетов до десятимиллиард. \n",
      "И все же наказание, которое терпит муха в десять тысяч раз более сурово, чем заслуживает подобный проступок. \n",
      "Закон десятитысячекратной кары строго соблюдается по отношению ко всем живым существам, включая и человека. Всякий долг, был ли он сделан сознательно или по незнанию, природа немедленно взыскивает еще на этом свете, не откладывая сведения счетов до десятимиллиард. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08d900>, {'not changed ,': 6, 'removed ,': 1, 'not changed .': 3, 'possible punctuation places': 64, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0})\n",
      "False\n",
      "===\n",
      "Библия точьвточь такова. Все сведения о существовании ее рая получены косвенным путем  от неизвестных лиц, которые ничем не доказали, что они бывали там сами. \n",
      "Если бы Христос действительно был богом, он мог бы доказать существование рая, поскольку для бога нет ничего невозможного. \n",
      "Библия точьвточь такова. Все сведения о существовании ее рая получены косвенным путем  от неизвестных лиц, которые ничем не доказали, что они бывали там сами. \n",
      "Если бы Христос действительно был богом, он мог бы доказать существование рая, поскольку для бога нет ничего невозможного. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08d900>, {'not changed .': 3, 'not changed ,': 4, 'possible punctuation places': 49, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Если бы не одна маленькая неувязка, это было бы абсолютно логичное построение, правильно отражающее всем известный характер богов, неувязка же эта заключается в произвольном и неправдоподобном предположении, будто одному человеку на сотню позволят избежать этого проклятия. Весьма мало вероятно, что в загробной жизни нас ждет рай. Чрезвычайно вероятно, что там нас ждет ад. \n",
      "Если бы не одна маленькая неувязка, это было бы абсолютно логичное построение, правильно отражающее всем известный характер богов, неувязка же эта заключается в произвольном и неправдоподобном предположении, будто одному человеку на сотню позволят избежать этого проклятия. Весьма мало вероятно, что в загробной жизни нас ждет рай. Чрезвычайно вероятно, что там нас ждет ад. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08e290>, {'not changed ,': 6, 'not changed .': 3, 'possible punctuation places': 62, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Его надо жалеть, а не упрекать, не презирать. Его швырнули в этот мир, не спрашивая его согласия, и он немедленно вбивает себе в голову, что имеет какието таинственные обязательства перед неизвестной силой, которая поступила с ним таким возмутительным образом, и с тех пор он считает, что несет ответственность перед этой силой за каждый свой поступок и подлежит наказанию за те из них, которые эта сила не одобряет. Однако тот же самый человек рассуждал бы совсем иначе, если бы какойнибудь земной тиран поработил его, наложил бы на него путы и потребовал бы слепой покорности. \n",
      "Его надо жалеть, а не упрекать, не презирать. Его швырнули в этот мир, не спрашивая его согласия, и он немедленно вбивает себе в голову, что имеет какието таинственные обязательства перед неизвестной силой, которая поступила с ним таким возмутительным образом, и с тех пор он считает, что несет ответственность перед этой силой за каждый свой поступок и подлежит наказанию за те из них, которые эта сила не одобряет. Однако тот же самый человек рассуждал бы совсем иначе, если бы какойнибудь земной тиран поработил его, наложил бы на него путы и потребовал бы слепой покорности. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08d900>, {'not changed ,': 11, 'not changed .': 3, 'possible punctuation places': 107, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n",
      "Его швырнули в этот мир, не спрашивая его согласия, и он немедленно вбивает себе в голову, что имеет какието таинственные обязательства перед неизвестной силой, которая поступила с ним таким возмутительным образом, и с тех пор он считает, что несет ответственность перед этой силой за каждый свой поступок и подлежит наказанию за те из них, которые эта сила не одобряет. Однако тот же самый человек рассуждал бы совсем иначе, если бы какойнибудь земной тиран поработил его, наложил бы на него путы и потребовал бы слепой покорности. Он заявил бы, что тиран не имел на это права, что тиран не имел права приказывать ему и требовать от него повиновения, что тиран не имел права вынуждать его совершать убийство, а потом возлагать на него ответственность за это убийство. \n",
      "Его швырнули в этот мир, не спрашивая его согласия, и он немедленно вбивает себе в голову, что имеет какието таинственные обязательства перед неизвестной силой, которая поступила с ним таким возмутительным образом, и с тех пор он считает, что несет ответственность перед этой силой за каждый свой поступок и подлежит наказанию за те из них, которые эта сила не одобряет. Однако тот же самый человек рассуждал бы совсем иначе, если бы какойнибудь земной тиран поработил его, наложил бы на него путы и потребовал бы слепой покорности. Он заявил бы, что тиран не имел на это права, что тиран не имел права приказывать ему и требовать от него повиновения, что тиран не имел права вынуждать его совершать убийство, а потом возлагать на него ответственность за это убийство. \n",
      "defaultdict(<function calculate_diff2.<locals>.<lambda> at 0x7fa4bb08e290>, {'not changed ,': 13, 'not changed .': 3, 'possible punctuation places': 141, 'changed , with .': 0, 'removed .': 0, 'added ,': 0, 'added .': 0, 'changed . with ,': 0, 'removed ,': 0})\n",
      "True\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "cnt = 0\n",
    "i = 0\n",
    "while i < len(txt):\n",
    "    if txt[i] != '.': \n",
    "        i += 1\n",
    "        continue\n",
    "    \n",
    "    cnt_dot = 0\n",
    "    j = i + 1\n",
    "    while j < len(txt):\n",
    "        if txt[j] == '.': \n",
    "            cnt_dot += 1\n",
    "            if cnt_dot == 3:\n",
    "                break\n",
    "        j += 1\n",
    "    if j + 1 >= len(txt):\n",
    "        break\n",
    "\n",
    "    t = txt[i + 2: j + 1]\n",
    "    i += 1\n",
    "\n",
    "    if len(set(\"–?!-…\\\\/*+-=#„}{;«:\") & set(t)) > 0:\n",
    "        continue\n",
    "    c = collections.Counter(t)\n",
    "    # if c['.'] < 4 or c[','] < 4:\n",
    "    if c[','] < 4:\n",
    "        continue\n",
    "\n",
    "    t = t.replace(\".\", \". \").replace(\",\", \", \").replace(\".  \", \". \").replace(\",  \", \", \")\n",
    "\n",
    "    text_to_infer = t.replace(\". \", \" \").replace(\", \", \" \")\n",
    "    res = await infer_optimal(params, text_to_infer)\n",
    "    diff = calculate_diff2(t, res)\n",
    "\n",
    "    #  + diff['removed ,']\n",
    "    if diff['changed , with .'] + diff['removed .'] + \\\n",
    "       diff['added ,'] + diff['added .'] + diff['changed . with ,'] > 0:\n",
    "        continue\n",
    "    if diff['removed ,'] >1:\n",
    "        continue\n",
    "    print(t)\n",
    "    print(res)\n",
    "    print(diff)\n",
    "    print(t==res)\n",
    "    print(\"===\")\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt > 20:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9820c5c763b00a27dae7bf4866daccb4144a4481e2eeab411be784c5ee08f3e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
