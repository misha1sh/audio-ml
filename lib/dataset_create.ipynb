{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc6e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imports\n",
    "import importlib\n",
    "importlib.reload(imports)\n",
    "from imports import *\n",
    "\n",
    "# https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html\n",
    "# http://opencorpora.org/dict.php?act=gram\n",
    "# https://github.com/pymorphy2/pymorphy2/blob/92d546f042ff14601376d3646242908d5ab786c1/pymorphy2/tagset.py#L130\n",
    "feature_tags_array = [\n",
    "    OpencorporaTag.PARTS_OF_SPEECH, # часть речи\n",
    "    OpencorporaTag.GENDERS, # род\n",
    "    OpencorporaTag.NUMBERS, # число\n",
    "    OpencorporaTag.CASES, # падеж\n",
    "    OpencorporaTag.ASPECTS, # соверш / несоверш\n",
    "    OpencorporaTag.TRANSITIVITY, # перех / непереходный\n",
    "    OpencorporaTag.PERSONS, # лицо\n",
    "    OpencorporaTag.TENSES, # время\n",
    "    OpencorporaTag.MOODS, # наклонение\n",
    "    OpencorporaTag.VOICES, # залог\n",
    "    #INVOLVEMENT\n",
    "    ['Prnt'], # вводные слова\n",
    "    ['Apro'], # местоимение\n",
    "    ['NUMB'], # число вида 1234\n",
    "    ['LATIN'], # текст на английском\n",
    "    ['UNKN'], # неизвестный токен\n",
    "    ['PUNCT_DASH', 'PUNCT_DOT', 'PUNCT_COMMA', 'PUNCT_QUOTE',\n",
    "     'PUNCT_LEFT_PARENTHESIS', 'PUNCT_RIGHT_PARENTHESIS' ], # \"()\n",
    "    ['CAPITALIZED'], # начинается с заглавной буквы\n",
    "    ['Fixd', 'Abbr'] # неизменяемое, сокращение\n",
    "]\n",
    "\n",
    "CUT_NAVEC_TAGS_ARRAY = [\n",
    "    #'NOUN', #'ADJF'\n",
    "]\n",
    "\n",
    "params = build_params({\n",
    "    \"VARIANTS_CNT\": 3,\n",
    "    \"TARGET_CLASSES_COUNT\": 3,\n",
    "    \"INPUT_WORDS_CNT\": 16,\n",
    "    \"feature_tags_array\": feature_tags_array,\n",
    "    \"PUNCTUATION_TARGET\": {\n",
    "        \"$empty\": NO_PUNCT,\n",
    "        \",\": 1,\n",
    "        \".\": 2,\n",
    "        \"!\": 2,\n",
    "        \"?\": 2,\n",
    "    },\n",
    "    \"USE_NAVEC\": True,\n",
    "    'CUT_NAVEC_TAGS_SET': set(CUT_NAVEC_TAGS_ARRAY),\n",
    "    'INFECTED_TEXT_PROB': 0.3,\n",
    "    \"RETAIN_LEFT_PUNCT\": True,\n",
    "    'type': 'lenta',\n",
    "    'NON_PUNCT_PROB': 1.0,\n",
    "    'INFECT_TYPE_PROBS': {\n",
    "        'REPLACE_UNDEF': 0.1,\n",
    "        'INCORRECT_PUNCT_RANDOM_PLACE': 0.1,\n",
    "        'INCORRECT_PUNCT_CENTER': 0.2,\n",
    "        'CORRECT_PUNCT_CENTER': 0.3,\n",
    "        'CORRECT_PUNCT_RIGHT': 0.3,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfbf6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('REPLACE_UNDEF',\n",
       "  'INCORRECT_PUNCT_RANDOM_PLACE',\n",
       "  'INCORRECT_PUNCT_CENTER',\n",
       "  'CORRECT_PUNCT_CENTER',\n",
       "  'CORRECT_PUNCT_RIGHT'),\n",
       " (0.1, 0.1, 0.2, 0.3, 0.3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27810932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CORRECT_PUNCT_RIGHT']\n",
      "['CORRECT_PUNCT_CENTER']\n",
      "['CORRECT_PUNCT_CENTER']\n",
      "['CORRECT_PUNCT_RIGHT']\n",
      "['INCORRECT_PUNCT_CENTER']\n",
      "['REPLACE_UNDEF']\n",
      "['CORRECT_PUNCT_RIGHT']\n",
      "['CORRECT_PUNCT_RIGHT']\n",
      "['CORRECT_PUNCT_RIGHT']\n",
      "['CORRECT_PUNCT_RIGHT']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(10):\n",
    "    print("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf25fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16) ['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'Привет', ',', 'тест', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'] {'VARIANTS_CNT': 3, 'TARGET_CLASSES_COUNT': 3, 'INPUT_WORDS_CNT': 16, 'PUNCTUATION_TARGET': {'$empty': 0, ',': 1, '.': 2, '!': 2, '?': 2}, 'USE_NAVEC': True, 'CUT_NAVEC_TAGS_SET': set(), 'INFECTED_TEXT_PROB': 0.3, 'RETAIN_LEFT_PUNCT': True, 'type': 'lenta', 'NON_PUNCT_PROB': 1.0, 'INFECT_TYPE_PROBS': {'REPLACE_UNDEF': 0.1, 'INCORRECT_PUNCT_RANDOM_PLACE': 0.1, 'INCORRECT_PUNCT_CENTER': 0.2, 'CORRECT_PUNCT_CENTER': 0.3, 'CORRECT_PUNCT_RIGHT': 0.3}, 'feature_tags_dict': {'1per': 0, '2per': 1, '3per': 2, 'ADJF': 3, 'ADJS': 4, 'ADVB': 5, 'Abbr': 6, 'Apro': 7, 'CAPITALIZED': 8, 'COMP': 9, 'CONJ': 10, 'Fixd': 11, 'GRND': 12, 'INFN': 13, 'INTJ': 14, 'LATIN': 15, 'NOUN': 16, 'NPRO': 17, 'NUMB': 18, 'NUMR': 19, 'PRCL': 20, 'PRED': 21, 'PREP': 22, 'PRTF': 23, 'PRTS': 24, 'PUNCT_COMMA': 25, 'PUNCT_DASH': 26, 'PUNCT_DOT': 27, 'PUNCT_LEFT_PARENTHESIS': 28, 'PUNCT_QUOTE': 29, 'PUNCT_RIGHT_PARENTHESIS': 30, 'Prnt': 31, 'UNKN': 32, 'VERB': 33, 'ablt': 34, 'acc2': 35, 'accs': 36, 'actv': 37, 'datv': 38, 'femn': 39, 'futr': 40, 'gen1': 41, 'gen2': 42, 'gent': 43, 'impf': 44, 'impr': 45, 'indc': 46, 'intr': 47, 'loc1': 48, 'loc2': 49, 'loct': 50, 'masc': 51, 'neut': 52, 'nomn': 53, 'past': 54, 'perf': 55, 'plur': 56, 'pres': 57, 'pssv': 58, 'sing': 59, 'tran': 60, 'voct': 61}, 'ID_TO_PUNCTUATION': {0: '$empty', 1: ',', 2: '.'}, 'INFECT_TYPE_TO_ID': {'nothing': 0, 'REPLACE_UNDEF': 1, 'INCORRECT_PUNCT_RANDOM_PLACE': 2, 'INCORRECT_PUNCT_CENTER': 3, 'CORRECT_PUNCT_CENTER': 4, 'CORRECT_PUNCT_RIGHT': 5}, 'ID_TO_INFECT_TYPE': {0: 'nothing', 1: 'REPLACE_UNDEF', 2: 'INCORRECT_PUNCT_RANDOM_PLACE', 3: 'INCORRECT_PUNCT_CENTER', 4: 'CORRECT_PUNCT_CENTER', 5: 'CORRECT_PUNCT_RIGHT'}, 'VARIANT_FEATURES_CNT': 63, 'EMBEDDING_FEATURES_CNT': 300, 'TOTAL_WORD_FEATURES_CNT': 489, 'VARIANT_PROB_IDX': 62, 'INPUT_WORDS_CNT_RIGHT': 8, 'INPUT_WORDS_CNT_LEFT': 8}\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16) ['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'Привет', ',', 'тест', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'] {'VARIANTS_CNT': 3, 'TARGET_CLASSES_COUNT': 3, 'INPUT_WORDS_CNT': 16, 'PUNCTUATION_TARGET': {'$empty': 0, ',': 1, '.': 2, '!': 2, '?': 2}, 'USE_NAVEC': True, 'CUT_NAVEC_TAGS_SET': set(), 'INFECTED_TEXT_PROB': 0.3, 'RETAIN_LEFT_PUNCT': True, 'type': 'lenta', 'NON_PUNCT_PROB': 1.0, 'INFECT_TYPE_PROBS': {'REPLACE_UNDEF': 0.1, 'INCORRECT_PUNCT_RANDOM_PLACE': 0.1, 'INCORRECT_PUNCT_CENTER': 0.2, 'CORRECT_PUNCT_CENTER': 0.3, 'CORRECT_PUNCT_RIGHT': 0.3}, 'feature_tags_dict': {'1per': 0, '2per': 1, '3per': 2, 'ADJF': 3, 'ADJS': 4, 'ADVB': 5, 'Abbr': 6, 'Apro': 7, 'CAPITALIZED': 8, 'COMP': 9, 'CONJ': 10, 'Fixd': 11, 'GRND': 12, 'INFN': 13, 'INTJ': 14, 'LATIN': 15, 'NOUN': 16, 'NPRO': 17, 'NUMB': 18, 'NUMR': 19, 'PRCL': 20, 'PRED': 21, 'PREP': 22, 'PRTF': 23, 'PRTS': 24, 'PUNCT_COMMA': 25, 'PUNCT_DASH': 26, 'PUNCT_DOT': 27, 'PUNCT_LEFT_PARENTHESIS': 28, 'PUNCT_QUOTE': 29, 'PUNCT_RIGHT_PARENTHESIS': 30, 'Prnt': 31, 'UNKN': 32, 'VERB': 33, 'ablt': 34, 'acc2': 35, 'accs': 36, 'actv': 37, 'datv': 38, 'femn': 39, 'futr': 40, 'gen1': 41, 'gen2': 42, 'gent': 43, 'impf': 44, 'impr': 45, 'indc': 46, 'intr': 47, 'loc1': 48, 'loc2': 49, 'loct': 50, 'masc': 51, 'neut': 52, 'nomn': 53, 'past': 54, 'perf': 55, 'plur': 56, 'pres': 57, 'pssv': 58, 'sing': 59, 'tran': 60, 'voct': 61}, 'ID_TO_PUNCTUATION': {0: '$empty', 1: ',', 2: '.'}, 'INFECT_TYPE_TO_ID': {'nothing': 0, 'REPLACE_UNDEF': 1, 'INCORRECT_PUNCT_RANDOM_PLACE': 2, 'INCORRECT_PUNCT_CENTER': 3, 'CORRECT_PUNCT_CENTER': 4, 'CORRECT_PUNCT_RIGHT': 5}, 'ID_TO_INFECT_TYPE': {0: 'nothing', 1: 'REPLACE_UNDEF', 2: 'INCORRECT_PUNCT_RANDOM_PLACE', 3: 'INCORRECT_PUNCT_CENTER', 4: 'CORRECT_PUNCT_CENTER', 5: 'CORRECT_PUNCT_RIGHT'}, 'VARIANT_FEATURES_CNT': 63, 'EMBEDDING_FEATURES_CNT': 300, 'TOTAL_WORD_FEATURES_CNT': 489, 'VARIANT_PROB_IDX': 62, 'INPUT_WORDS_CNT_RIGHT': 8, 'INPUT_WORDS_CNT_LEFT': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.2949, -0.0562, -0.1937],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.2949, -0.0562, -0.1937],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.2949, -0.0562, -0.1937]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.2949, -0.0562, -0.1937],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.2949, -0.0562, -0.1937],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.2949, -0.0562, -0.1937],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([0, 1, 0, 0]),\n",
       " [['PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   ' #$empty# ',\n",
       "   'Привет',\n",
       "   'тест',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD'],\n",
       "  ['PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'Привет',\n",
       "   ' #,# ',\n",
       "   'тест',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD'],\n",
       "  ['PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'UNDEF',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'Привет',\n",
       "   'UNDEF',\n",
       "   ' #$empty# ',\n",
       "   'тест',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   'UNDEF'],\n",
       "  ['PAD',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   'PAD',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   ' #$empty# ',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   'UNDEF',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'PAD',\n",
       "   'UNDEF',\n",
       "   'PAD']],\n",
       " tensor([False, False,  True,  True]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset_builder\n",
    "dataset_builder.create_dataset_for_text(\"Привет, тест\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373823a-aabb-4da3-93d7-88b3a8734740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "server = run_server_if_not_running()\n",
    "server_install_packages(server)\n",
    "\n",
    "# server.rpc_simple(dataset_builder.get_word_features, 'кошка', params).shape\n",
    "# server.rpc_simple(dataset_builder.create_dataset, ['а, б'], params, False)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is listening on 0.0.0.0:65231\n",
      "Connected by ('51.250.1.213', 46672)\n",
      "write_task started\n",
      "submit task\n",
      "submit task\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "237.23245239257812 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 1\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "273.5552673339844 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 2\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "256.3638610839844 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 109\u001b[0m\n\u001b[1;32m    107\u001b[0m stream \u001b[39m=\u001b[39m Stream(get_lenta_records())\u001b[39m.\u001b[39mskip(\u001b[39m5000\u001b[39m)\u001b[39m.\u001b[39mlimit(\u001b[39m200_000\u001b[39m)\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m record: record\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    108\u001b[0m writer \u001b[39m=\u001b[39m AsyncDatasetWriter(server)\n\u001b[0;32m--> 109\u001b[0m writer\u001b[39m.\u001b[39;49mload_dataset(stream)\n",
      "Cell \u001b[0;32mIn[3], line 96\u001b[0m, in \u001b[0;36mAsyncDatasetWriter.load_dataset\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m stream\u001b[39m.\u001b[39mgroup(params[\u001b[39m\"\u001b[39m\u001b[39mchunk_size\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthread_write\u001b[39m.\u001b[39mis_alive(): \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_count\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m     98\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msubmit task\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m     future \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrpc_server\u001b[39m.\u001b[39mrpc_async(dataset_builder\u001b[39m.\u001b[39mcreate_dataset, chunk, params, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch-env/envs/pytorch-env/lib/python3.10/threading.py:467\u001b[0m, in \u001b[0;36mSemaphore.acquire\u001b[0;34m(self, blocking, timeout)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[39mif\u001b[39;00m timeout \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    466\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    468\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch-env/envs/pytorch-env/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "256.8414001464844 MB\n",
      "writing finished\n",
      "chunks_count 4\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "244.36569213867188 MB\n",
      "writing finished\n",
      "chunks_count 5\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "274.2864990234375 MB\n",
      "writing finished\n",
      "chunks_count 6\n"
     ]
    }
   ],
   "source": [
    "params[\"train_test_split\"] = 0.9\n",
    "params[\"chunk_size\"] = 300 # 3000 # 300000\n",
    "params[\"batch_size\"] = 20000\n",
    "params[\"max_parallel\"] = 3\n",
    "params[\"type\"] = \"lenta\"\n",
    "\n",
    "params[\"max_last_read_queue_size\"] = 1\n",
    "\n",
    "\n",
    "class AsyncDatasetWriter:\n",
    "    def __init__(self, rpc_server):\n",
    "        self.storage = Storage(\"cache2/storage\")\n",
    "        self.storage.clear()\n",
    "        self.chunks_count = 0\n",
    "\n",
    "        self.storage.write_meta(\"chunks_count\", 0)\n",
    "        self.storage.write_meta(\"params\", params)\n",
    "\n",
    "        self.parallel_count = threading.Semaphore(params[\"max_parallel\"])\n",
    "        self.write_queue = queue.Queue()\n",
    "        # self.thread_write = threading.Thread(target=asyncio.run, args=(self.write_task(),))\n",
    "        \n",
    "        self.device = torch.device('cuda:0')\n",
    "\n",
    "        self.chunks_iter = None\n",
    "        self.rpc_server = rpc_server\n",
    "        \n",
    "        self.thread_write = threading.Thread(target=self.write_task)\n",
    "        self.thread_write.start()\n",
    "        \n",
    "        \n",
    "    def chunk_loaded_callback(self, future):\n",
    "        print(\"chunk_loaded_callback\")\n",
    "        self.write_queue.put(future)\n",
    "\n",
    "    def has_free_space(self):\n",
    "        free_space_gb = shutil.disk_usage(self.storage.path).free / 1024 / 1024 / 1024\n",
    "        if free_space_gb < 5:\n",
    "            print(f\"Out of disk space. Remainging {free_space_gb} GB\")\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "\n",
    "    def write(self, future, i):\n",
    "        if not self.has_free_space(): return\n",
    "        # if future.exception() is not None:\n",
    "        #     future.\n",
    "            # absprint(\"ERROR: \", future.exception(), \"\\n\", \n",
    "                    # \"\\n\".join(traceback.format_tb(future.traceback())  ))\n",
    "            # raise future.exception()\n",
    "        print(\"getting result started\")\n",
    "        print(future)\n",
    "        x, y, text_res, is_infected = future.get_result()\n",
    "        print(\"writing started\")\n",
    "        print(size_of_tensor(x) / 1024 / 1024, \"MB\")\n",
    "        self.storage.store(\"x\", i, x)\n",
    "        self.storage.store(\"y\", i, y)\n",
    "        self.storage.store(\"text_res\", i, text_res)\n",
    "        self.storage.store(\"is_infected\", i, is_infected)\n",
    "        self.parallel_count.release()\n",
    "        self.write_queue.task_done()\n",
    "        print(\"writing finished\")\n",
    "        self.chunks_count += 1\n",
    "        print(\"chunks_count\", self.chunks_count)\n",
    "        self.storage.write_meta(\"chunks_count\", self.chunks_count)\n",
    "\n",
    "    def write_task(self):        \n",
    "        try:\n",
    "            print(\"write_task started\")\n",
    "            keep_running = True        \n",
    "            def handle_executor_done_callback(future):\n",
    "                nonlocal keep_running\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR\", \"writer thread failed:\\n\", type(e).__name__, e)\n",
    "                    print(\"\\n\".join(traceback.format_tb(e.__traceback__)))\n",
    "                    keep_running = False\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor(params[\"max_parallel\"], \"WRITER\") as executor:\n",
    "                chunk_number = 0\n",
    "                while keep_running:\n",
    "                    if not self.has_free_space(): return\n",
    "                    future = executor.submit(self.write, self.write_queue.get(), chunk_number)\n",
    "                    future.add_done_callback(handle_executor_done_callback)\n",
    "                    chunk_number += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"ERROR\", \"writer thread failed:\\n\", type(e).__name__, e)\n",
    "            print(\"\\n\".join(traceback.format_tb(e.__traceback__)))\n",
    "    \n",
    "    def load_dataset(self, stream):\n",
    "        # with concurrent.futures.ThreadPoolExecutor(max_workers=params[\"max_parallel\"]) as executor:\n",
    "        for chunk in stream.group(params[\"chunk_size\"]):\n",
    "            if not self.thread_write.is_alive(): return\n",
    "            self.parallel_count.acquire()\n",
    "\n",
    "            print(\"submit task\")\n",
    "            future = self.rpc_server.rpc_async(dataset_builder.create_dataset, chunk, params, False)\n",
    "            future.set_callback(self.chunk_loaded_callback)\n",
    "            future = None\n",
    "        \n",
    "        \n",
    "from dataset_lib import get_lenta_records\n",
    "server = run_server_if_not_running()\n",
    "server_install_packages(server)\n",
    "stream = Stream(get_lenta_records()).skip(5000).limit(200_000).map(lambda record: record.text)\n",
    "writer = AsyncDatasetWriter(server)\n",
    "writer.load_dataset(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1c2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "9\n",
      "2009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Kek:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "    \n",
    "    def read(self, cnt=-1): \n",
    "        print(cnt)\n",
    "        return self.a.read(cnt)\n",
    "    def readline(self): raise Exception(\"no realization\")\n",
    "    def readable(self): return True\n",
    "\n",
    "    def write(self, buf):\n",
    "        print(len(buf))\n",
    "\n",
    "import io\n",
    "import dill\n",
    "\n",
    "a = Kek(io.BytesIO())\n",
    "\n",
    "dill.dump([\"kek\"] * 1000, a)\n",
    "\n",
    "# Reset the position of the BytesIO object to the beginning\n",
    "a.a.seek(0)\n",
    "\n",
    "# Pass the BytesIO object directly to the Kek class\n",
    "a.a.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
