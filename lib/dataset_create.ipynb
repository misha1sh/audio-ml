{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc6e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imports\n",
    "import importlib\n",
    "importlib.reload(imports)\n",
    "from imports import *\n",
    "\n",
    "# https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html\n",
    "# http://opencorpora.org/dict.php?act=gram\n",
    "# https://github.com/pymorphy2/pymorphy2/blob/92d546f042ff14601376d3646242908d5ab786c1/pymorphy2/tagset.py#L130\n",
    "feature_tags_array = [\n",
    "    OpencorporaTag.PARTS_OF_SPEECH, # часть речи\n",
    "    OpencorporaTag.GENDERS, # род\n",
    "    OpencorporaTag.NUMBERS, # число\n",
    "    OpencorporaTag.CASES, # падеж\n",
    "    OpencorporaTag.ASPECTS, # соверш / несоверш\n",
    "    OpencorporaTag.TRANSITIVITY, # перех / непереходный\n",
    "    OpencorporaTag.PERSONS, # лицо\n",
    "    OpencorporaTag.TENSES, # время\n",
    "    OpencorporaTag.MOODS, # наклонение\n",
    "    OpencorporaTag.VOICES, # залог\n",
    "    #INVOLVEMENT\n",
    "    ['Prnt'], # вводные слова\n",
    "    ['Apro'], # местоимение\n",
    "    ['NUMB'], # число вида 1234\n",
    "    ['LATIN'], # текст на английском\n",
    "    ['UNKN'], # неизвестный токен\n",
    "    ['PUNCT_DASH', 'PUNCT_DOT', 'PUNCT_COMMA', 'PUNCT_QUOTE',\n",
    "     'PUNCT_LEFT_PARENTHESIS', 'PUNCT_RIGHT_PARENTHESIS' ], # \"()\n",
    "    ['CAPITALIZED'], # начинается с заглавной буквы\n",
    "    ['Fixd', 'Abbr'] # неизменяемое, сокращение\n",
    "]\n",
    "\n",
    "CUT_NAVEC_TAGS_ARRAY = [\n",
    "    #'NOUN', #'ADJF'\n",
    "]\n",
    "\n",
    "params = build_params({\n",
    "    \"VARIANTS_CNT\": 1,\n",
    "    \"TARGET_CLASSES_COUNT\": 3,\n",
    "    \"INPUT_WORDS_CNT\": 16,\n",
    "    \"feature_tags_array\": feature_tags_array,\n",
    "    \"PUNCTUATION_TARGET\": {\n",
    "        \"$empty\": NO_PUNCT,\n",
    "        \",\": 1,\n",
    "        \".\": 2,\n",
    "        \"!\": 2,\n",
    "        \"?\": 2,\n",
    "    },\n",
    "    \"USE_NAVEC\": True,\n",
    "    'CUT_NAVEC_TAGS_SET': set(CUT_NAVEC_TAGS_ARRAY),\n",
    "    'INFECTED_TEXT_PROB': 0.1,\n",
    "    \"RETAIN_LEFT_PUNCT\": True,\n",
    "    'type': 'lenta',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7373823a-aabb-4da3-93d7-88b3a8734740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is listening on 0.0.0.0:65231\n",
      "Connected by ('51.250.1.213', 39862)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = run_server_if_not_running()\n",
    "server_install_packages(server)\n",
    "\n",
    "# server.rpc_simple(dataset_builder.get_word_features, 'кошка', params).shape\n",
    "# server.rpc_simple(dataset_builder.create_dataset, ['а, б'], params, False)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is listening on 0.0.0.0:65231\n",
      "Connected by ('51.250.1.213', 49650)\n",
      "write_task started\n",
      "submit task\n",
      "submit task\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1425.4906311035156 MB\n",
      "writing finished\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1236.46875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1089.7422180175781 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1060.7181701660156 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1103.9662170410156 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1144.1900024414062 MB\n",
      "writing finished\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1143.1597595214844 MB\n",
      "writing finishedsubmit task\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1163.177490234375 MB\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1129.0686950683594 MB\n",
      "writing finished\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "1129.0686950683594 MB\n",
      "writing finished\n",
      "writing finished\n"
     ]
    }
   ],
   "source": [
    "params[\"train_test_split\"] = 0.9\n",
    "params[\"chunk_size\"] = 3000 # 3000 # 300000\n",
    "params[\"batch_size\"] = 20000\n",
    "params[\"max_parallel\"] = 3\n",
    "params[\"type\"] = \"lenta\"\n",
    "\n",
    "params[\"max_last_read_queue_size\"] = 1\n",
    "\n",
    "\n",
    "class AsyncDatasetWriter:\n",
    "    def __init__(self, rpc_server):\n",
    "        self.storage = Storage(\"cache/storage\")\n",
    "        self.storage.clear()\n",
    "        self.chunks_count = 0\n",
    "\n",
    "        self.storage.write_meta(\"chunks_count\", 0)\n",
    "        self.storage.write_meta(\"params\", params)\n",
    "\n",
    "        self.parallel_count = threading.Semaphore(params[\"max_parallel\"])\n",
    "        self.write_queue = queue.Queue()\n",
    "        # self.thread_write = threading.Thread(target=asyncio.run, args=(self.write_task(),))\n",
    "        \n",
    "        self.chunks_cnt = 0\n",
    "        self.device = torch.device('cuda:0')\n",
    "\n",
    "        self.chunks_iter = None\n",
    "        self.rpc_server = rpc_server\n",
    "        \n",
    "        self.thread_write = threading.Thread(target=self.write_task)\n",
    "        self.thread_write.start()\n",
    "        \n",
    "        \n",
    "    def chunk_loaded_callback(self, future):\n",
    "        print(\"chunk_loaded_callback\")\n",
    "        self.write_queue.put(future)\n",
    "\n",
    "    def write(self, future, i):\n",
    "        # if future.exception() is not None:\n",
    "        #     future.\n",
    "            # absprint(\"ERROR: \", future.exception(), \"\\n\", \n",
    "                    # \"\\n\".join(traceback.format_tb(future.traceback())  ))\n",
    "            # raise future.exception()\n",
    "        print(\"getting result started\")\n",
    "        print(future)\n",
    "        x, y, text_res, is_infected = future.get_result()\n",
    "        print(\"writing started\")\n",
    "        print(size_of_tensor(x) / 1024 / 1024, \"MB\")\n",
    "        self.storage.store(\"x\", i, x)\n",
    "        self.storage.store(\"y\", i, y)\n",
    "        self.storage.store(\"text_res\", i, text_res)\n",
    "        self.storage.store(\"is_infected\", i, is_infected)\n",
    "        self.parallel_count.release()\n",
    "        self.write_queue.task_done()\n",
    "        print(\"writing finished\")\n",
    "\n",
    "    def write_task(self):        \n",
    "        try:\n",
    "            print(\"write_task started\")\n",
    "            keep_running = True        \n",
    "            def handle_executor_done_callback(future):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR\", \"writer thread failed:\\n\", type(e).__name__, e)\n",
    "                    print(\"\\n\".join(traceback.format_tb(e.__traceback__)))\n",
    "                    keep_running = False\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor(params[\"max_parallel\"], \"WRITER\") as executor:\n",
    "                chunk_number = 0\n",
    "                while keep_running:\n",
    "                    future = executor.submit(self.write, self.write_queue.get(), chunk_number)\n",
    "                    future.add_done_callback(handle_executor_done_callback)\n",
    "                    chunk_number += 1\n",
    "                    self.chunks_count += 1\n",
    "\n",
    "                    self.storage.write_meta(\"chunks_count\", self.chunks_count)\n",
    "        except Exception as e:\n",
    "            print(\"ERROR\", \"writer thread failed:\\n\", type(e).__name__, e)\n",
    "            print(\"\\n\".join(traceback.format_tb(e.__traceback__)))\n",
    "    \n",
    "    def load_dataset(self, stream):\n",
    "        # with concurrent.futures.ThreadPoolExecutor(max_workers=params[\"max_parallel\"]) as executor:\n",
    "        for chunk in stream.group(params[\"chunk_size\"]):\n",
    "            if not self.thread_write.is_alive(): return\n",
    "            self.parallel_count.acquire()\n",
    "\n",
    "            print(\"submit task\")\n",
    "            future = self.rpc_server.rpc_async(dataset_builder.create_dataset, chunk, params, False)\n",
    "            future.set_callback(self.chunk_loaded_callback)\n",
    "            future = None\n",
    "        \n",
    "        \n",
    "from dataset_lib import get_lenta_records\n",
    "server = run_server_if_not_running()\n",
    "server_install_packages(server)\n",
    "stream = Stream(get_lenta_records()).limit(30000).map(lambda record: record.text)\n",
    "writer = AsyncDatasetWriter(server)\n",
    "writer.load_dataset(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1c2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "9\n",
      "2009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Kek:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "    \n",
    "    def read(self, cnt=-1): \n",
    "        print(cnt)\n",
    "        return self.a.read(cnt)\n",
    "    def readline(self): raise Exception(\"no realization\")\n",
    "    def readable(self): return True\n",
    "\n",
    "    def write(self, buf):\n",
    "        print(len(buf))\n",
    "\n",
    "import io\n",
    "import dill\n",
    "\n",
    "a = Kek(io.BytesIO())\n",
    "\n",
    "dill.dump([\"kek\"] * 1000, a)\n",
    "\n",
    "# Reset the position of the BytesIO object to the beginning\n",
    "a.a.seek(0)\n",
    "\n",
    "# Pass the BytesIO object directly to the Kek class\n",
    "a.a.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
