{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc6e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imports\n",
    "import importlib\n",
    "importlib.reload(imports)\n",
    "from imports import *\n",
    "\n",
    "# https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html\n",
    "# http://opencorpora.org/dict.php?act=gram\n",
    "# https://github.com/pymorphy2/pymorphy2/blob/92d546f042ff14601376d3646242908d5ab786c1/pymorphy2/tagset.py#L130\n",
    "feature_tags_array = [\n",
    "    OpencorporaTag.PARTS_OF_SPEECH, # часть речи\n",
    "    OpencorporaTag.GENDERS, # род\n",
    "    OpencorporaTag.NUMBERS, # число\n",
    "    OpencorporaTag.CASES, # падеж\n",
    "    OpencorporaTag.ASPECTS, # соверш / несоверш\n",
    "    OpencorporaTag.TRANSITIVITY, # перех / непереходный\n",
    "    OpencorporaTag.PERSONS, # лицо\n",
    "    OpencorporaTag.TENSES, # время\n",
    "    OpencorporaTag.MOODS, # наклонение\n",
    "    OpencorporaTag.VOICES, # залог\n",
    "    #INVOLVEMENT\n",
    "    ['Prnt'], # вводные слова\n",
    "    ['Apro'], # местоимение\n",
    "    ['NUMB'], # число вида 1234\n",
    "    ['LATIN'], # текст на английском\n",
    "    ['UNKN'], # неизвестный токен\n",
    "    ['PUNCT_DASH', 'PUNCT_DOT', 'PUNCT_COMMA', 'PUNCT_QUOTE',\n",
    "     'PUNCT_LEFT_PARENTHESIS', 'PUNCT_RIGHT_PARENTHESIS' ], # \"()\n",
    "    ['CAPITALIZED'], # начинается с заглавной буквы\n",
    "    ['Fixd', 'Abbr'] # неизменяемое, сокращение\n",
    "]\n",
    "\n",
    "CUT_NAVEC_TAGS_ARRAY = [\n",
    "    #'NOUN', #'ADJF'\n",
    "]\n",
    "\n",
    "params = build_params({\n",
    "    \"VARIANTS_CNT\": 3,\n",
    "    \"TARGET_CLASSES_COUNT\": 3,\n",
    "    \"INPUT_WORDS_CNT\": 32,\n",
    "    \"feature_tags_array\": feature_tags_array,\n",
    "    \"PUNCTUATION_TARGET\": {\n",
    "        \"$empty\": NO_PUNCT,\n",
    "        \",\": 1,\n",
    "        \".\": 2,\n",
    "        \"!\": 2,\n",
    "        \"?\": 2,\n",
    "    },\n",
    "    \"USE_NAVEC\": True,\n",
    "    'CUT_NAVEC_TAGS_SET': set(CUT_NAVEC_TAGS_ARRAY),\n",
    "    \"RETAIN_LEFT_PUNCT\": True,\n",
    "    'type': 'lenta',\n",
    "    'NON_PUNCT_PROB': 1.0,\n",
    "\n",
    "    'INFECTED_TEXT_PROB': 0.5,\n",
    "    'INFECT_TYPE_PROBS': {\n",
    "        'REPLACE_UNDEF': 0.1,\n",
    "        'INCORRECT_PUNCT_RANDOM_PLACE': 0.1,\n",
    "        'INCORRECT_PUNCT_CENTER': 0.2,\n",
    "        'CORRECT_PUNCT_CENTER': 0.3,\n",
    "        'CORRECT_PUNCT_RIGHT': 0.3,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cf25fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[None, 'PAD', ' #$empty# ', 'тест', None],\n",
       "  ['PAD', 'Привет', ' #,# ', 'тест', 'это'],\n",
       "  ['Привет', ',', ' #$empty# ', '.', 'это'],\n",
       "  [',', 'тест', ' #.# ', 'это', 'тест'],\n",
       "  ['тест', '.', ' #$empty# ', 'тест', '.'],\n",
       "  ['.', 'это', ' #$empty# ', 'PAD', None],\n",
       "  ['это', 'тест', ' #.# ', 'PAD', None],\n",
       "  ['тест', '.', ' #$empty# ', 'PAD', 'PAD']],\n",
       " tensor([3, 1, 5, 5, 5, 3, 3, 5], dtype=torch.uint8))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import dataset_builder\n",
    "importlib.reload(dataset_builder)\n",
    "\n",
    "dataset_builder.create_dataset_for_text(\"Привет, тест. это тест.\", params)[2:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd98b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 489])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset_builder\n",
    "dataset_builder.create_dataset_for_text(\"Привет, тест\", params)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373823a-aabb-4da3-93d7-88b3a8734740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "server = run_server_if_not_running()\n",
    "server_install_packages(server)\n",
    "\n",
    "# server.rpc_simple(dataset_builder.get_word_features, 'кошка', params).shape\n",
    "# server.rpc_simple(dataset_builder.create_dataset, ['а, б'], params, False)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server already running\n",
      "write_task started\n",
      "submit task\n",
      "submit task\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "474.46490478515625 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 1\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "547.1105346679688 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 2\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "512.7277221679688 MB\n",
      "writing finished\n",
      "chunks_count 3\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "513.6828002929688 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 4\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "488.73138427734375 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 5\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "548.572998046875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 6\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "518.010498046875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 7\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "492.7606201171875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 8\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "457.63165283203125 MB\n",
      "writing finished\n",
      "chunks_count 9\n",
      "submit task\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "506.6092529296875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 10\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "542.4246826171875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 11\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "544.8123779296875 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 12\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "460.97442626953125 MB\n",
      "writing finishedsubmit task\n",
      "\n",
      "chunks_count 13\n",
      "chunk_loaded_callback\n",
      "getting result started\n",
      "BasicAsyncResult completed with result `(tensor([[[ 0.0000, ...`\n",
      "writing started\n",
      "466.22735595703125 MB\n"
     ]
    }
   ],
   "source": [
    "params[\"train_test_split\"] = 0.9\n",
    "params[\"chunk_size\"] = 100 # 3000 # 300000\n",
    "params[\"batch_size\"] = 20000\n",
    "params[\"max_parallel\"] = 3\n",
    "params[\"type\"] = \"lenta\"\n",
    "\n",
    "params[\"max_last_read_queue_size\"] = 1\n",
    "\n",
    "\n",
    "class AsyncDatasetWriter:\n",
    "    def __init__(self, rpc_server):\n",
    "        self.storage = Storage(\"cache2/storage\")\n",
    "        self.storage.clear()\n",
    "        self.chunks_count = 0\n",
    "\n",
    "        self.storage.write_meta(\"chunks_count\", 0)\n",
    "        self.storage.write_meta(\"params\", params)\n",
    "\n",
    "        self.parallel_count = threading.Semaphore(params[\"max_parallel\"])\n",
    "        self.write_queue = queue.Queue()\n",
    "        # self.thread_write = threading.Thread(target=asyncio.run, args=(self.write_task(),))\n",
    "        \n",
    "        self.device = torch.device('cuda:0')\n",
    "\n",
    "        self.chunks_iter = None\n",
    "        self.rpc_server = rpc_server\n",
    "        \n",
    "        self.thread_write = threading.Thread(target=self.write_task)\n",
    "        self.thread_write.start()\n",
    "        \n",
    "        \n",
    "    def chunk_loaded_callback(self, future):\n",
    "        print(\"chunk_loaded_callback\")\n",
    "        self.write_queue.put(future)\n",
    "\n",
    "    def has_free_space(self):\n",
    "        free_space_gb = shutil.disk_usage(self.storage.path).free / 1024 / 1024 / 1024\n",
    "        if free_space_gb < 5:\n",
    "            print(f\"Out of disk space. Remainging {free_space_gb} GB\")\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "\n",
    "    def write(self, future, i):\n",
    "        if not self.has_free_space(): return\n",
    "        # if future.exception() is not None:\n",
    "        #     future.\n",
    "            # absprint(\"ERROR: \", future.exception(), \"\\n\", \n",
    "                    # \"\\n\".join(traceback.format_tb(future.traceback())  ))\n",
    "            # raise future.exception()\n",
    "        print(\"getting result started\")\n",
    "        print(future)\n",
    "        x, y, text_res, is_infected = future.get_result()\n",
    "        print(\"writing started\")\n",
    "        print(size_of_tensor(x) / 1024 / 1024, \"MB\")\n",
    "        self.storage.store(\"x\", i, x)\n",
    "        self.storage.store(\"y\", i, y)\n",
    "        self.storage.store(\"text_res\", i, text_res)\n",
    "        self.storage.store(\"is_infected\", i, is_infected)\n",
    "        self.parallel_count.release()\n",
    "        self.write_queue.task_done()\n",
    "        print(\"writing finished\")\n",
    "        self.chunks_count += 1\n",
    "        print(\"chunks_count\", self.chunks_count)\n",
    "        self.storage.write_meta(\"chunks_count\", self.chunks_count)\n",
    "\n",
    "    def write_task(self):        \n",
    "        try:\n",
    "            print(\"write_task started\")\n",
    "            keep_running = True        \n",
    "            def handle_executor_done_callback(future):\n",
    "                nonlocal keep_running\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR\", \"writer thread failed:\\n\", type(e).__name__, e)\n",
    "                    print(\"\\n\".join(traceback.format_tb(e.__traceback__)))\n",
    "                    keep_running = False\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor(params[\"max_parallel\"], \"WRITER\") as executor:\n",
    "                chunk_number = 0\n",
    "                while keep_running:\n",
    "                    if not self.has_free_space(): return\n",
    "                    future = executor.submit(self.write, self.write_queue.get(), chunk_number)\n",
    "                    future.add_done_callback(handle_executor_done_callback)\n",
    "                    chunk_number += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"ERROR\", \"writer thread failed:\\n\", type(e).__name__, e)\n",
    "            print(\"\\n\".join(traceback.format_tb(e.__traceback__)))\n",
    "    \n",
    "    def load_dataset(self, stream):\n",
    "        # with concurrent.futures.ThreadPoolExecutor(max_workers=params[\"max_parallel\"]) as executor:\n",
    "        for chunk in stream.group(params[\"chunk_size\"]):\n",
    "            if not self.thread_write.is_alive(): return\n",
    "            self.parallel_count.acquire()\n",
    "\n",
    "            print(\"submit task\")\n",
    "            future = self.rpc_server.rpc_async(dataset_builder.create_dataset, chunk, params, False)\n",
    "            future.set_callback(self.chunk_loaded_callback)\n",
    "            future = None\n",
    "        \n",
    "        \n",
    "from dataset_lib import get_lenta_records\n",
    "server = run_server_if_not_running()\n",
    "server_install_packages(server)\n",
    "stream = Stream(get_lenta_records()).skip(5000).limit(200_000).map(lambda record: record.text)\n",
    "writer = AsyncDatasetWriter(server)\n",
    "writer.load_dataset(stream)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1c2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "9\n",
      "2009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Kek:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "    \n",
    "    def read(self, cnt=-1): \n",
    "        print(cnt)\n",
    "        return self.a.read(cnt)\n",
    "    def readline(self): raise Exception(\"no realization\")\n",
    "    def readable(self): return True\n",
    "\n",
    "    def write(self, buf):\n",
    "        print(len(buf))\n",
    "\n",
    "import io\n",
    "import dill\n",
    "\n",
    "a = Kek(io.BytesIO())\n",
    "\n",
    "dill.dump([\"kek\"] * 1000, a)\n",
    "\n",
    "# Reset the position of the BytesIO object to the beginning\n",
    "a.a.seek(0)\n",
    "\n",
    "# Pass the BytesIO object directly to the Kek class\n",
    "a.a.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
