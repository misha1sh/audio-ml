{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb87e6",
   "metadata": {
    "cellId": "imezge4b9mmfalbn59pg3o"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/mdeff/fma.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9a928e",
   "metadata": {
    "cellId": "5lnjqptfje958zyr30gmlc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fef1bc",
   "metadata": {
    "cellId": "s65tshgjeatw4453aym2i"
   },
   "outputs": [],
   "source": [
    "#!c1.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c861d1",
   "metadata": {
    "cellId": "qg1x52eqfw9tzb0odh9yu"
   },
   "outputs": [],
   "source": [
    "#!:bash\n",
    "#pragma dataset init fma_small --size 20Gb\n",
    "set -e\n",
    "\n",
    "cd /home/jupyter/mnt/datasets/fma_small\n",
    "\n",
    "wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip -P ./\n",
    "echo \"f0df49ffe5f2a6008d7dc83c6915b31835dfe733  ./fma_metadata.zip\" | sha1sum -c -\n",
    "7z x ./fma_metadata.zip -o./\n",
    "rm -rf fma_metadata.zip\n",
    "\n",
    "wget https://os.unil.cloud.switch.ch/fma/fma_small.zip -P ./\n",
    "echo \"ade154f733639d52e35e32f5593efe5be76c6d70  ./fma_small.zip\" | sha1sum -c -\n",
    "7z x ./fma_small.zip -o./\n",
    "rm -rf fma_small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d01c4",
   "metadata": {
    "cellId": "ttswzc7kdbr9xm1e0z6108",
    "execution_id": "5fda763d-f8d2-4835-ad4e-7ce5c6153ff3"
   },
   "outputs": [],
   "source": [
    "#!:bash\n",
    "#pragma dataset init fma_medium --size 50Gb\n",
    "set -e\n",
    "\n",
    "cd /home/jupyter/mnt/datasets/fma_medium\n",
    "\n",
    "wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip -P ./\n",
    "echo \"f0df49ffe5f2a6008d7dc83c6915b31835dfe733  ./fma_metadata.zip\" | sha1sum -c -\n",
    "7z x ./fma_metadata.zip -o./\n",
    "rm -rf fma_metadata.zip\n",
    "\n",
    "wget https://os.unil.cloud.switch.ch/fma/fma_medium.zip -P ./\n",
    "echo \"c67b69ea232021025fca9231fc1c7c1a063ab50b  fma_medium.zip\"   | sha1sum -c -\n",
    "7z x ./fma_medium.zip -o./\n",
    "rm -rf fma_medium.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e59a5",
   "metadata": {
    "cellId": "4gnxr297oq2hrfdhj82wxs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e15958",
   "metadata": {
    "cellId": "ks37m9043toy2nn3lg5nj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32675b66",
   "metadata": {
    "cellId": "1tyx9t82mzwbgxqiimm2sc"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db8c3c",
   "metadata": {
    "cellId": "tr2sa7ensei0s34v6gchhsa"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "#pragma async\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e35bb6",
   "metadata": {
    "cellId": "qt81bbnhr7ex9yox5w71h"
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv kapre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737a152",
   "metadata": {
    "cellId": "peptd81woat5q9luje5l8a"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import fma.utils as fma\n",
    "import IPython.display as ipd\n",
    "\n",
    "PREFIX = \"/home/jupyter/mnt/datasets/fma_small/\"\n",
    "AUDIO_DIR = PREFIX + \"fma_small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa109e",
   "metadata": {
    "cellId": "qi4gwk3o086pdsu7zc558"
   },
   "outputs": [],
   "source": [
    "tracks = fma.load(PREFIX + 'fma_metadata/tracks.csv')\n",
    "genres = fma.load(PREFIX + 'fma_metadata/genres.csv')\n",
    "\n",
    "small = tracks[tracks['set', 'subset'] <= 'small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d8085",
   "metadata": {
    "cellId": "ww1fnbxveka96zlbsxccjk"
   },
   "outputs": [],
   "source": [
    "filename = fma.get_audio_path(AUDIO_DIR, 2)\n",
    "x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "print('Duration: {:.2f}s, {} samples'.format(x.shape[-1] / sr, x.size))\n",
    "\n",
    "best_sr = 5000\n",
    "x = librosa.resample(x, sr, best_sr)\n",
    "\n",
    "start, end = 7, 17\n",
    "ipd.Audio(data=x[start*best_sr:end*best_sr], rate=best_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cb30e",
   "metadata": {
    "cellId": "qcdokrx1gnwq93ckr3voi"
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed \n",
    "import time\n",
    "\n",
    "class ProgressParallel(Parallel):\n",
    "    def __init__(self, use_tqdm=True, total=None, *args, **kwargs):\n",
    "        self._use_tqdm = use_tqdm\n",
    "        self._total = total\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with tqdm(disable=not self._use_tqdm, total=self._total) as self._pbar:\n",
    "            return Parallel.__call__(self, *args, **kwargs)\n",
    "\n",
    "    def print_progress(self):\n",
    "        if self._total is None:\n",
    "            self._pbar.total = self.n_dispatched_tasks\n",
    "        self._pbar.n = self.n_completed_tasks\n",
    "        self._pbar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478463fc",
   "metadata": {
    "cellId": "kzt3o6ajybgu1vjc6ha7u"
   },
   "outputs": [
    {
     "ename": "Execute error",
     "evalue": "Servant c1.4 not allocated: Allocation was interrupted",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed \n",
    "from audioread.exceptions import NoBackendError\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore', message=\".*PySoundFile.*\")\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 4096\n",
    "LENGTH_SECONDS = 1.0\n",
    "LENGTH = int(round((LENGTH_SECONDS * SAMPLE_RATE)))\n",
    "\n",
    "COUNT = 8000\n",
    "\n",
    "def extract_audio(i, row):\n",
    "    warnings.filterwarnings('ignore', message=\".*PySoundFile.*\")\n",
    "    filename = fma.get_audio_path(AUDIO_DIR, i)\n",
    "    try:\n",
    "        data, sr = librosa.load(filename, sr=SAMPLE_RATE, mono=True, duration=LENGTH_SECONDS + 0.01)\n",
    "        if len(data) < LENGTH:\n",
    "            return None\n",
    "        \n",
    "        data = data[0: LENGTH]\n",
    "        return data, row[\"track\"][\"genre_top\"]\n",
    "    except NoBackendError:\n",
    "        return None\n",
    "\n",
    "def get_dataset():\n",
    "    tracks_to_parse = list(itertools.islice(small.iterrows(), COUNT))\n",
    "    task = [delayed(extract_audio)(i, row) for i, row in tracks_to_parse]\n",
    "    dataset = ProgressParallel(n_jobs=4, total=len(tracks_to_parse))(task)\n",
    "    print(\"dataset\", len(dataset))\n",
    "    dataset = [i for i in dataset if i is not None]\n",
    "    print(\"filtered\", len(dataset))\n",
    "    x, y = zip(*dataset)\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    print(\"x, y\", x.shape, y.shape)\n",
    "    return x, y\n",
    "    \n",
    "def prepare_dataset():\n",
    "    x, y = get_dataset()\n",
    "\n",
    "    np.save(\"x\", x)\n",
    "    np.save(\"y\", y)\n",
    "    print(\"success\")\n",
    "\n",
    "prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d497a70",
   "metadata": {
    "cellId": "e1psovewooglvov9tjotsb"
   },
   "outputs": [],
   "source": [
    "tracks_to_parse = list(itertools.islice(small.iterrows(), COUNT))\n",
    "a, b = extract_audio(*tracks_to_parse[2])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63fd65",
   "metadata": {
    "cellId": "qf8as5te6iqejvjr6upe"
   },
   "outputs": [],
   "source": [
    "len(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b805fd6",
   "metadata": {
    "cellId": "6op7pcqfi3a7fsy4r0z9su"
   },
   "outputs": [],
   "source": [
    "x = np.load(\"x.npy\")\n",
    "y = np.load(\"y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a719d",
   "metadata": {
    "cellId": "d9wsbzbi2lr3h95pf20xw7"
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47b91c",
   "metadata": {
    "cellId": "gygu7e9pstz82kgu4o6h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_train_test(x, y):\n",
    "    df = pd.DataFrame(data={'col1': y})\n",
    "    y_cat = pd.get_dummies(df['col1']).to_numpy()\n",
    "    return train_test_split(x, y_cat, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fa46f",
   "metadata": {
    "cellId": "60hhfpbkls9hy1nw56mxa"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_train_test(np.load(\"x.npy\"), np.load(\"y.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad2fe2",
   "metadata": {
    "cellId": "1302ps1cjrj91g1fv143y"
   },
   "outputs": [],
   "source": [
    "\n",
    "Parallel(n_jobs=10)(delayed(time.sleep)(i ** 2) for i in tqdm(range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd104d",
   "metadata": {
    "cellId": "nksuohh1vkkiue8b2n5wj7"
   },
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143cf8c",
   "metadata": {
    "cellId": "f4krg4eace58tuwyot6l3"
   },
   "outputs": [],
   "source": [
    "np.sum(y_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960449bf",
   "metadata": {
    "cellId": "nbdpdv4ex7alzzgedg503g"
   },
   "outputs": [],
   "source": [
    "np.sum(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a0e54",
   "metadata": {
    "cellId": "8l25zserl747mnf6gvwfdb"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5dda9",
   "metadata": {
    "cellId": "izmt8pomf6dzt8ohehytg"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "import kapre\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Softmax, Activation\n",
    "from kapre import STFT, Magnitude, MagnitudeToDecibel\n",
    "from kapre.composed import get_melspectrogram_layer, get_log_frequency_spectrogram_layer\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "input_shape = (LENGTH, 1)\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(STFT(n_fft=2048, win_length=2048, hop_length=1024,\n",
    "#                window_name=None, pad_end=False,\n",
    "#                input_data_format='channels_last', output_data_format='channels_last',\n",
    "#                input_shape=input_shape))\n",
    "\n",
    "model.add(STFT(n_fft=4096, win_length=4096, hop_length=2048,\n",
    "               window_name=\"hann_window\", pad_end=False,\n",
    "               input_data_format='channels_last', output_data_format='channels_last',\n",
    "               input_shape=input_shape))\n",
    "\n",
    "\n",
    "model.add(Magnitude())\n",
    "model.add(MagnitudeToDecibel())\n",
    "\n",
    "# model.add(Dense(50))\n",
    "model.add(Activation(activations.tanh))\n",
    "model.add(Dense(50))\n",
    "model.add(ReLU())\n",
    "model.add(Dense(50))\n",
    "# model.add(Conv2D(32, (3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(8))\n",
    "model.add(Softmax())\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.0001), 'categorical_crossentropy', 'categorical_accuracy')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de961b",
   "metadata": {
    "cellId": "pa0m3rwhayemy364oc1nw"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8caaeccc",
   "metadata": {
    "cellId": "ij80gr9w1ko9sunran4y6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 9)\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "def test():\n",
    "    import numpy as np\n",
    "    import librosa\n",
    "    x = np.load(\"x.npy\")\n",
    "    print(librosa.stft(x[0]).shape)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71fb3fa1",
   "metadata": {
    "cellId": "edp4o8ebcgf9sb8wukrx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "\n",
    "def get_x_stft(x):\n",
    "    import numpy as np\n",
    "    import librosa\n",
    "    \n",
    "    x = np.load(\"x.npy\")\n",
    "    x_stft = []\n",
    "    for i in x[:]:\n",
    "        x_stft.append(librosa.stft(i))\n",
    "\n",
    "    x_stft = np.array(x_stft)\n",
    "    \n",
    "    return x_stft\n",
    "\n",
    "def nnorm(x_stft):\n",
    "    import numpy as np\n",
    "    aa = np.ma.log2(np.abs(x_stft) + 1).filled(0)\n",
    "    mmin = 0 #np.min(aa), \n",
    "    mmax = 10 # np.max(aa)\n",
    "    mag = (aa - mmin) / (mmax - mmin)\n",
    "    ang = (np.angle(x_stft) + np.pi) / 2 / np.pi\n",
    "    \n",
    "    return np.dstack((mag, ang))\n",
    "\n",
    "def denorm(mag_ang):\n",
    "    import numpy as np\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "    \n",
    "    mmin = 0 \n",
    "    mmax = 10\n",
    "    \n",
    "    aa = mag * (mmax - mmin) + mmin\n",
    "    aa = np.exp2(aa) - 1\n",
    "    ang2 = ang * 2 * np.pi - np.pi\n",
    "    \n",
    "    return aa * np.exp(1j*ang2)\n",
    "\n",
    "def get_ddata(x_stft):\n",
    "    import numpy as np\n",
    "    mag_ang = nnorm(x_stft)\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "#     return mag[:, :, 0:2]\n",
    "    return mag[:, :, 0:]\n",
    "#     return np.dstack((mag[:, :, 0], ang[:, :, 0]))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = prepare_train_test(x_stft, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "24c99199",
   "metadata": {
    "cellId": "kzdd5h15w9kyp8y48merr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7996, 1025, 9)\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "\n",
    "def test():\n",
    "    import numpy as np\n",
    "    print(get_ddata(get_x_stft(np.load(\"x.npy\"))).shape  )\n",
    "#     x_stft = get_x_stft(np.load(\"x.npy\"))\n",
    "#     mag_ang = nnorm(x_stft)\n",
    "#     mag, ang = np.dsplit(mag_ang, 2)\n",
    "#     print(mag.shape)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005adce",
   "metadata": {
    "cellId": "gzfl1tidceixnq7v9tkwti"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "np.min(get_ddata(get_x_stft(np.load(\"x.npy\")))), np.max(get_ddata(get_x_stft(np.load(\"x.npy\")))), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03aaa6fa",
   "metadata": {
    "cellId": "mpjlds3hz3bt6xuqck8ki"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b54abe",
   "metadata": {
    "cellId": "it4ns0yu8iewpwomyoi7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 16 18:38:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GRID A100X-1-5C     On   | 00000000:8C:00.0 Off |                   On |\n",
      "| N/A   N/A    P0    N/A /  N/A |                  N/A |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    0   0   0  |    720MiB /  5115MiB | 14      0 |  1   0    0    0    0 |\n",
      "|                  |      0MiB /  1024MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e57cd2",
   "metadata": {
    "cellId": "oh19k1upgjdxst187dazk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "\n",
    "def model_predict_mag(model, mag):\n",
    "    import numpy as np\n",
    "    pred_mag_1024 = model.predict(mag[:, :1024, :])\n",
    "    mag_1025 = np.concatenate((pred_mag_1024, mag[:, 1024:1025, :]), axis=-2)\n",
    "    return mag_1025\n",
    "\n",
    "def getAutoencoder():\n",
    "    from keras import Model\n",
    "    class Autoencoder(Model):\n",
    "        def __init__(self):\n",
    "            super(Autoencoder, self).__init__()\n",
    "            from keras.layers import Conv2D, Conv1D, BatchNormalization, ReLU, MaxPooling1D, UpSampling1D, Dense, Softmax, Reshape, Flatten, Input\n",
    "            import tensorflow as tf\n",
    "            \n",
    "            input_shape = (1024, 9)\n",
    "            self.encoder = tf.keras.Sequential([\n",
    "                Input(input_shape),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=1, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                Dense(16, activation='tanh'),\n",
    "            ])\n",
    "            self.decoder = tf.keras.Sequential([\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                UpSampling1D(size=2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                UpSampling1D(size=2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                UpSampling1D(size=2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                UpSampling1D(size=2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                Conv1D(filters=9, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                Reshape( (1024, 9) ),\n",
    "            ])\n",
    "\n",
    "        def call(self, x):\n",
    "            encoded = self.encoder(x)\n",
    "            decoded = self.decoder(encoded)\n",
    "            return decoded\n",
    "        \n",
    "        def save(self):\n",
    "            self.encoder.save('encoder.keras')\n",
    "            self.decoder.save('decoder.keras')\n",
    "            \n",
    "        def load(self):\n",
    "            from keras.models import load_model\n",
    "            self.encoder = load_model(\"encoder.keras\")\n",
    "            self.decoder = load_model(\"decoder.keras\")\n",
    "        \n",
    "    return Autoencoder\n",
    "\n",
    "\n",
    "def run():\n",
    "    import numpy as np\n",
    "    print(\"loading_data\")\n",
    "    mag_ang = get_ddata(get_x_stft(np.load(\"x.npy\")))\n",
    "    print(\"importing\")\n",
    "    from keras import Model\n",
    "    from keras.models import Sequential\n",
    "    # from kapre import InverseSTFT, STFT, Magnitude, MagnitudeToDecibel\n",
    "    # from kapre.composed import get_melspectrogram_layer, get_log_frequency_spectrogram_layer\n",
    "    from keras.backend import cast as Cast\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    import tensorflow as tf\n",
    "    print(\"preparing\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "    normalizer.adapt(mag_ang)\n",
    "    \n",
    "# #     model.add(Flatten())\n",
    "# #     model.add(BatchNormalization())\n",
    "# #     model.add(Dense(1025 * 1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    autoencoder = getAutoencoder()()\n",
    "    #learning_rate=0.05 learning_rate=0.001 binary_crossentropy\n",
    "    autoencoder.compile(Adam(), 'mean_squared_error', 'mean_absolute_error')\n",
    "\n",
    "    print(\"training\")\n",
    "    import datetime\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    #\n",
    "    def my_callback(*args, **kwargs):\n",
    "        import numpy as np\n",
    "        m1, a1 = np.dsplit(model.predict(mag_ang[:1, :, :]), 2)\n",
    "        m2, a2 = np.dsplit(mag_ang[:1, :, :], 2)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(m1.reshape(1025)[:100])\n",
    "        plt.plot(m2.reshape(1025)[:100])\n",
    "        plt.show()\n",
    "        \n",
    "    def my_callback2(*args, **kwargs):\n",
    "        import numpy as np\n",
    "        m1 = model_predict_mag(autoencoder, mag_ang[:1, :, :])\n",
    "        m2 = mag_ang[:1, :, :]\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(m1[:, :, 0].reshape(1025)[:100])\n",
    "        plt.plot(m2[:, :, 0].reshape(1025)[:100])\n",
    "        plt.show()\n",
    "        \n",
    "    def scheduler(epoch):\n",
    "        if epoch % 5 == 4:\n",
    "            autoencoder.save()\n",
    "        if epoch < 30:\n",
    "            return 0.001\n",
    "        elif epoch < 100:\n",
    "            return 0.0005\n",
    "        else:\n",
    "            return 0.0001\n",
    "        \n",
    "    autoencoder.fit(mag_ang[:50, :1024, :], mag_ang[:50, :1024, :], epochs=600, \n",
    "            callbacks=[tensorboard_callback, tf.keras.callbacks.LambdaCallback(on_epoch_end=my_callback2),\n",
    "                       tf.keras.callbacks.LearningRateScheduler(scheduler)], validation_split=0.2)\n",
    "    autoencoder.save()\n",
    "    \n",
    "    \n",
    "def run_proc(task):\n",
    "    import multiprocessing\n",
    "    print(\"starting proc\")\n",
    "    p = multiprocessing.Process(target=task)\n",
    "    try:\n",
    "        p.start()\n",
    "        p.join()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"terminating proccess\")\n",
    "        p.terminate()\n",
    "        from time import sleep\n",
    "        sleep(1)\n",
    "        print(\"killing\")\n",
    "        p.kill()\n",
    "    \n",
    "# run_proc(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b8e67",
   "metadata": {
    "cellId": "c2bvl0324qb6weh1lsgkwo"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb10dd",
   "metadata": {
    "cellId": "h8joxq3kkw6sj37wg2d5zd"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e43650a",
   "metadata": {
    "cellId": "cfvij6uljdhq5bzxtr2es8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting proc\n",
      "reading and calculating stft\n",
      "preparing y\n",
      "proccessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 18:44:22.836232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-16 18:44:23.269180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: GRID A100X-1-5C MIG 1g.5gb, pci bus id: 0000:8c:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7996, 1024, 9) (7996, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 18:44:23.763567: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 18:44:25.902550: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-09-16 18:44:27.037299: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 - 5s - loss: 2.5315 - categorical_accuracy: 0.1595 - val_loss: 2.1721 - val_categorical_accuracy: 0.1781\n",
      "Epoch 2/100\n",
      "200/200 - 2s - loss: 2.2809 - categorical_accuracy: 0.1704 - val_loss: 1.8721 - val_categorical_accuracy: 0.2988\n",
      "Epoch 3/100\n",
      "200/200 - 1s - loss: 2.1256 - categorical_accuracy: 0.1887 - val_loss: 1.8476 - val_categorical_accuracy: 0.3094\n",
      "Epoch 4/100\n",
      "200/200 - 1s - loss: 2.0428 - categorical_accuracy: 0.2073 - val_loss: 1.8845 - val_categorical_accuracy: 0.2775\n",
      "Epoch 5/100\n",
      "200/200 - 2s - loss: 1.9531 - categorical_accuracy: 0.2481 - val_loss: 1.9078 - val_categorical_accuracy: 0.2506\n",
      "Epoch 6/100\n",
      "200/200 - 1s - loss: 1.9163 - categorical_accuracy: 0.2569 - val_loss: 2.0311 - val_categorical_accuracy: 0.2606\n",
      "Epoch 7/100\n",
      "200/200 - 1s - loss: 1.8613 - categorical_accuracy: 0.2942 - val_loss: 1.7454 - val_categorical_accuracy: 0.3200\n",
      "Epoch 8/100\n",
      "200/200 - 1s - loss: 1.8491 - categorical_accuracy: 0.2971 - val_loss: 1.7442 - val_categorical_accuracy: 0.3381\n",
      "Epoch 9/100\n",
      "200/200 - 1s - loss: 1.8217 - categorical_accuracy: 0.3074 - val_loss: 1.8913 - val_categorical_accuracy: 0.2937\n",
      "Epoch 10/100\n",
      "200/200 - 2s - loss: 1.8203 - categorical_accuracy: 0.3091 - val_loss: 1.7236 - val_categorical_accuracy: 0.3469\n",
      "Epoch 11/100\n",
      "200/200 - 1s - loss: 1.7815 - categorical_accuracy: 0.3265 - val_loss: 2.2341 - val_categorical_accuracy: 0.2688\n",
      "Epoch 12/100\n",
      "200/200 - 1s - loss: 1.7738 - categorical_accuracy: 0.3288 - val_loss: 2.3198 - val_categorical_accuracy: 0.2506\n",
      "Epoch 13/100\n",
      "200/200 - 1s - loss: 1.7555 - categorical_accuracy: 0.3419 - val_loss: 1.9232 - val_categorical_accuracy: 0.2831\n",
      "Epoch 14/100\n",
      "200/200 - 1s - loss: 1.7377 - categorical_accuracy: 0.3530 - val_loss: 1.7983 - val_categorical_accuracy: 0.3475\n",
      "Epoch 15/100\n",
      "200/200 - 2s - loss: 1.7206 - categorical_accuracy: 0.3583 - val_loss: 1.9276 - val_categorical_accuracy: 0.2988\n",
      "Epoch 16/100\n",
      "200/200 - 1s - loss: 1.7047 - categorical_accuracy: 0.3655 - val_loss: 2.0640 - val_categorical_accuracy: 0.3044\n",
      "Epoch 17/100\n",
      "200/200 - 2s - loss: 1.6821 - categorical_accuracy: 0.3768 - val_loss: 1.6979 - val_categorical_accuracy: 0.3656\n",
      "Epoch 18/100\n",
      "200/200 - 2s - loss: 1.6842 - categorical_accuracy: 0.3784 - val_loss: 1.7374 - val_categorical_accuracy: 0.3787\n",
      "Epoch 19/100\n",
      "200/200 - 1s - loss: 1.6706 - categorical_accuracy: 0.3845 - val_loss: 2.1132 - val_categorical_accuracy: 0.3063\n",
      "Epoch 20/100\n",
      "200/200 - 2s - loss: 1.6487 - categorical_accuracy: 0.3924 - val_loss: 1.7492 - val_categorical_accuracy: 0.3506\n",
      "Epoch 21/100\n",
      "200/200 - 1s - loss: 1.6361 - categorical_accuracy: 0.4004 - val_loss: 1.6742 - val_categorical_accuracy: 0.3750\n",
      "Epoch 22/100\n",
      "200/200 - 1s - loss: 1.6151 - categorical_accuracy: 0.4087 - val_loss: 1.7257 - val_categorical_accuracy: 0.3744\n",
      "Epoch 23/100\n",
      "200/200 - 1s - loss: 1.5990 - categorical_accuracy: 0.4157 - val_loss: 1.7876 - val_categorical_accuracy: 0.3487\n",
      "Epoch 24/100\n",
      "200/200 - 1s - loss: 1.5842 - categorical_accuracy: 0.4203 - val_loss: 1.7465 - val_categorical_accuracy: 0.3688\n",
      "Epoch 25/100\n",
      "200/200 - 2s - loss: 1.5616 - categorical_accuracy: 0.4278 - val_loss: 1.7753 - val_categorical_accuracy: 0.3656\n",
      "Epoch 26/100\n",
      "200/200 - 2s - loss: 1.5600 - categorical_accuracy: 0.4342 - val_loss: 1.8834 - val_categorical_accuracy: 0.3469\n",
      "Epoch 27/100\n",
      "200/200 - 1s - loss: 1.5519 - categorical_accuracy: 0.4398 - val_loss: 1.7276 - val_categorical_accuracy: 0.3756\n",
      "Epoch 28/100\n",
      "200/200 - 1s - loss: 1.5290 - categorical_accuracy: 0.4464 - val_loss: 1.9113 - val_categorical_accuracy: 0.3212\n",
      "Epoch 29/100\n",
      "200/200 - 1s - loss: 1.5258 - categorical_accuracy: 0.4489 - val_loss: 1.7829 - val_categorical_accuracy: 0.3600\n",
      "Epoch 30/100\n",
      "200/200 - 2s - loss: 1.5032 - categorical_accuracy: 0.4601 - val_loss: 1.8849 - val_categorical_accuracy: 0.3363\n",
      "Epoch 31/100\n",
      "200/200 - 1s - loss: 1.5064 - categorical_accuracy: 0.4536 - val_loss: 1.6992 - val_categorical_accuracy: 0.3856\n",
      "Epoch 32/100\n",
      "200/200 - 1s - loss: 1.4795 - categorical_accuracy: 0.4570 - val_loss: 1.7622 - val_categorical_accuracy: 0.3956\n",
      "Epoch 33/100\n",
      "200/200 - 1s - loss: 1.4452 - categorical_accuracy: 0.4780 - val_loss: 1.6831 - val_categorical_accuracy: 0.4112\n",
      "Epoch 34/100\n",
      "200/200 - 2s - loss: 1.4453 - categorical_accuracy: 0.4794 - val_loss: 1.8555 - val_categorical_accuracy: 0.3319\n",
      "Epoch 35/100\n",
      "200/200 - 2s - loss: 1.4480 - categorical_accuracy: 0.4769 - val_loss: 1.7518 - val_categorical_accuracy: 0.3950\n",
      "Epoch 36/100\n",
      "200/200 - 1s - loss: 1.4277 - categorical_accuracy: 0.4778 - val_loss: 1.7906 - val_categorical_accuracy: 0.3794\n",
      "Epoch 37/100\n",
      "200/200 - 1s - loss: 1.4155 - categorical_accuracy: 0.4878 - val_loss: 1.8626 - val_categorical_accuracy: 0.3650\n",
      "Epoch 38/100\n",
      "200/200 - 1s - loss: 1.4214 - categorical_accuracy: 0.4897 - val_loss: 1.7381 - val_categorical_accuracy: 0.3969\n",
      "Epoch 39/100\n",
      "200/200 - 1s - loss: 1.4014 - categorical_accuracy: 0.4978 - val_loss: 1.8382 - val_categorical_accuracy: 0.3556\n",
      "Epoch 40/100\n",
      "200/200 - 2s - loss: 1.3994 - categorical_accuracy: 0.4947 - val_loss: 1.8394 - val_categorical_accuracy: 0.3356\n",
      "Epoch 41/100\n",
      "200/200 - 2s - loss: 1.3746 - categorical_accuracy: 0.5055 - val_loss: 1.8078 - val_categorical_accuracy: 0.3706\n",
      "Epoch 42/100\n",
      "200/200 - 1s - loss: 1.3753 - categorical_accuracy: 0.5022 - val_loss: 1.7876 - val_categorical_accuracy: 0.3744\n",
      "Epoch 43/100\n",
      "200/200 - 1s - loss: 1.3681 - categorical_accuracy: 0.5131 - val_loss: 1.7798 - val_categorical_accuracy: 0.3594\n",
      "Epoch 44/100\n",
      "200/200 - 1s - loss: 1.3650 - categorical_accuracy: 0.5133 - val_loss: 1.7694 - val_categorical_accuracy: 0.3700\n",
      "Epoch 45/100\n",
      "200/200 - 2s - loss: 1.3254 - categorical_accuracy: 0.5217 - val_loss: 1.8171 - val_categorical_accuracy: 0.3769\n",
      "Epoch 46/100\n",
      "200/200 - 1s - loss: 1.3462 - categorical_accuracy: 0.5125 - val_loss: 1.7796 - val_categorical_accuracy: 0.3806\n",
      "Epoch 47/100\n",
      "200/200 - 1s - loss: 1.3261 - categorical_accuracy: 0.5310 - val_loss: 1.8705 - val_categorical_accuracy: 0.3762\n",
      "Epoch 48/100\n",
      "200/200 - 1s - loss: 1.3041 - categorical_accuracy: 0.5328 - val_loss: 1.8097 - val_categorical_accuracy: 0.3775\n",
      "Epoch 49/100\n",
      "200/200 - 1s - loss: 1.2921 - categorical_accuracy: 0.5363 - val_loss: 1.9602 - val_categorical_accuracy: 0.3656\n",
      "Epoch 50/100\n",
      "200/200 - 2s - loss: 1.2843 - categorical_accuracy: 0.5405 - val_loss: 1.7691 - val_categorical_accuracy: 0.3844\n",
      "Epoch 51/100\n",
      "200/200 - 1s - loss: 1.2877 - categorical_accuracy: 0.5317 - val_loss: 2.1337 - val_categorical_accuracy: 0.3537\n",
      "Epoch 52/100\n",
      "200/200 - 1s - loss: 1.2886 - categorical_accuracy: 0.5374 - val_loss: 1.8846 - val_categorical_accuracy: 0.3725\n",
      "Epoch 53/100\n",
      "200/200 - 1s - loss: 1.2518 - categorical_accuracy: 0.5538 - val_loss: 1.8287 - val_categorical_accuracy: 0.3725\n",
      "Epoch 54/100\n",
      "200/200 - 2s - loss: 1.2504 - categorical_accuracy: 0.5566 - val_loss: 1.9011 - val_categorical_accuracy: 0.3625\n",
      "Epoch 55/100\n",
      "200/200 - 2s - loss: 1.2677 - categorical_accuracy: 0.5500 - val_loss: 2.0134 - val_categorical_accuracy: 0.3344\n",
      "Epoch 56/100\n",
      "200/200 - 1s - loss: 1.2484 - categorical_accuracy: 0.5538 - val_loss: 2.0201 - val_categorical_accuracy: 0.3431\n",
      "Epoch 57/100\n",
      "200/200 - 2s - loss: 1.2493 - categorical_accuracy: 0.5558 - val_loss: 1.8448 - val_categorical_accuracy: 0.3650\n",
      "Epoch 58/100\n",
      "200/200 - 1s - loss: 1.2757 - categorical_accuracy: 0.5413 - val_loss: 1.8722 - val_categorical_accuracy: 0.3656\n",
      "Epoch 59/100\n",
      "200/200 - 1s - loss: 1.2483 - categorical_accuracy: 0.5575 - val_loss: 2.3503 - val_categorical_accuracy: 0.2875\n",
      "Epoch 60/100\n",
      "200/200 - 2s - loss: 1.2461 - categorical_accuracy: 0.5543 - val_loss: 1.8600 - val_categorical_accuracy: 0.3638\n",
      "Epoch 61/100\n",
      "200/200 - 1s - loss: 1.2084 - categorical_accuracy: 0.5705 - val_loss: 1.9217 - val_categorical_accuracy: 0.3869\n",
      "Epoch 62/100\n",
      "200/200 - 1s - loss: 1.2152 - categorical_accuracy: 0.5704 - val_loss: 1.7992 - val_categorical_accuracy: 0.3750\n",
      "Epoch 63/100\n",
      "200/200 - 1s - loss: 1.2123 - categorical_accuracy: 0.5696 - val_loss: 1.9873 - val_categorical_accuracy: 0.3525\n",
      "Epoch 64/100\n",
      "200/200 - 1s - loss: 1.1931 - categorical_accuracy: 0.5741 - val_loss: 1.9187 - val_categorical_accuracy: 0.3525\n",
      "Epoch 65/100\n",
      "200/200 - 2s - loss: 1.1897 - categorical_accuracy: 0.5744 - val_loss: 2.0511 - val_categorical_accuracy: 0.3281\n",
      "Epoch 66/100\n",
      "200/200 - 1s - loss: 1.2006 - categorical_accuracy: 0.5729 - val_loss: 1.9537 - val_categorical_accuracy: 0.3713\n",
      "Epoch 67/100\n",
      "200/200 - 1s - loss: 1.1848 - categorical_accuracy: 0.5865 - val_loss: 1.9331 - val_categorical_accuracy: 0.3619\n",
      "Epoch 68/100\n",
      "200/200 - 1s - loss: 1.1775 - categorical_accuracy: 0.5786 - val_loss: 1.8537 - val_categorical_accuracy: 0.3731\n",
      "Epoch 69/100\n",
      "200/200 - 1s - loss: 1.1777 - categorical_accuracy: 0.5785 - val_loss: 2.0478 - val_categorical_accuracy: 0.3350\n",
      "Epoch 70/100\n",
      "200/200 - 2s - loss: 1.1528 - categorical_accuracy: 0.5905 - val_loss: 1.9798 - val_categorical_accuracy: 0.3262\n",
      "Epoch 71/100\n",
      "200/200 - 2s - loss: 1.1833 - categorical_accuracy: 0.5671 - val_loss: 2.0004 - val_categorical_accuracy: 0.3125\n",
      "Epoch 72/100\n",
      "200/200 - 1s - loss: 1.1943 - categorical_accuracy: 0.5779 - val_loss: 1.9449 - val_categorical_accuracy: 0.3475\n",
      "Epoch 73/100\n",
      "200/200 - 1s - loss: 1.1413 - categorical_accuracy: 0.5932 - val_loss: 1.9534 - val_categorical_accuracy: 0.3731\n",
      "Epoch 74/100\n",
      "200/200 - 1s - loss: 1.1156 - categorical_accuracy: 0.6048 - val_loss: 1.9646 - val_categorical_accuracy: 0.3500\n",
      "Epoch 75/100\n",
      "200/200 - 2s - loss: 1.1364 - categorical_accuracy: 0.5904 - val_loss: 2.0989 - val_categorical_accuracy: 0.3506\n",
      "Epoch 76/100\n",
      "200/200 - 1s - loss: 1.1703 - categorical_accuracy: 0.5894 - val_loss: 1.9629 - val_categorical_accuracy: 0.3481\n",
      "Epoch 77/100\n",
      "200/200 - 1s - loss: 1.1130 - categorical_accuracy: 0.6098 - val_loss: 1.9344 - val_categorical_accuracy: 0.3469\n",
      "Epoch 78/100\n",
      "200/200 - 1s - loss: 1.1325 - categorical_accuracy: 0.5916 - val_loss: 2.0098 - val_categorical_accuracy: 0.3375\n",
      "Epoch 79/100\n",
      "200/200 - 1s - loss: 1.1405 - categorical_accuracy: 0.5965 - val_loss: 1.9673 - val_categorical_accuracy: 0.3812\n",
      "Epoch 80/100\n",
      "200/200 - 2s - loss: 1.1146 - categorical_accuracy: 0.6010 - val_loss: 2.0760 - val_categorical_accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "200/200 - 1s - loss: 1.1031 - categorical_accuracy: 0.6060 - val_loss: 1.9466 - val_categorical_accuracy: 0.3519\n",
      "Epoch 82/100\n",
      "200/200 - 1s - loss: 1.1115 - categorical_accuracy: 0.6026 - val_loss: 2.0859 - val_categorical_accuracy: 0.3200\n",
      "Epoch 83/100\n",
      "200/200 - 1s - loss: 1.1086 - categorical_accuracy: 0.6098 - val_loss: 1.9614 - val_categorical_accuracy: 0.3512\n",
      "Epoch 84/100\n",
      "200/200 - 1s - loss: 1.0981 - categorical_accuracy: 0.6091 - val_loss: 1.9844 - val_categorical_accuracy: 0.3494\n",
      "Epoch 85/100\n",
      "200/200 - 2s - loss: 1.0819 - categorical_accuracy: 0.6254 - val_loss: 2.0202 - val_categorical_accuracy: 0.3631\n",
      "Epoch 86/100\n",
      "200/200 - 1s - loss: 1.1445 - categorical_accuracy: 0.5947 - val_loss: 1.8879 - val_categorical_accuracy: 0.3856\n",
      "Epoch 87/100\n",
      "200/200 - 1s - loss: 1.0941 - categorical_accuracy: 0.6099 - val_loss: 2.0099 - val_categorical_accuracy: 0.3569\n",
      "Epoch 88/100\n",
      "200/200 - 1s - loss: 1.0875 - categorical_accuracy: 0.6238 - val_loss: 1.9593 - val_categorical_accuracy: 0.3531\n",
      "Epoch 89/100\n",
      "200/200 - 1s - loss: 1.1100 - categorical_accuracy: 0.6083 - val_loss: 1.8996 - val_categorical_accuracy: 0.3806\n",
      "Epoch 90/100\n",
      "200/200 - 2s - loss: 1.0770 - categorical_accuracy: 0.6166 - val_loss: 2.0669 - val_categorical_accuracy: 0.3363\n",
      "Epoch 91/100\n",
      "200/200 - 2s - loss: 1.0842 - categorical_accuracy: 0.6241 - val_loss: 1.9999 - val_categorical_accuracy: 0.3475\n",
      "Epoch 92/100\n",
      "200/200 - 2s - loss: 1.0892 - categorical_accuracy: 0.6119 - val_loss: 1.9617 - val_categorical_accuracy: 0.3306\n",
      "Epoch 93/100\n",
      "200/200 - 2s - loss: 1.1013 - categorical_accuracy: 0.6066 - val_loss: 2.0817 - val_categorical_accuracy: 0.3487\n",
      "Epoch 94/100\n",
      "200/200 - 2s - loss: 1.0620 - categorical_accuracy: 0.6243 - val_loss: 2.0719 - val_categorical_accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "200/200 - 2s - loss: 1.0598 - categorical_accuracy: 0.6265 - val_loss: 2.1020 - val_categorical_accuracy: 0.3644\n",
      "Epoch 96/100\n",
      "200/200 - 1s - loss: 1.0514 - categorical_accuracy: 0.6262 - val_loss: 2.0900 - val_categorical_accuracy: 0.3331\n",
      "Epoch 97/100\n",
      "200/200 - 1s - loss: 1.0559 - categorical_accuracy: 0.6270 - val_loss: 2.0040 - val_categorical_accuracy: 0.3606\n",
      "Epoch 98/100\n",
      "200/200 - 1s - loss: 1.0568 - categorical_accuracy: 0.6243 - val_loss: 2.0296 - val_categorical_accuracy: 0.3512\n",
      "Epoch 99/100\n",
      "200/200 - 2s - loss: 1.0213 - categorical_accuracy: 0.6406 - val_loss: 2.0872 - val_categorical_accuracy: 0.3575\n",
      "Epoch 100/100\n",
      "200/200 - 2s - loss: 1.0604 - categorical_accuracy: 0.6270 - val_loss: 2.0717 - val_categorical_accuracy: 0.3456\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "def run():\n",
    "    import numpy as np\n",
    "    print(\"reading and calculating stft\")\n",
    "    mag_ang = nnorm(get_x_stft(np.load(\"x.npy\")))\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "    \n",
    "    print(\"preparing y\")\n",
    "    import pandas as pd\n",
    "    y = np.load(\"y.npy\")\n",
    "    df = pd.DataFrame(data={'col1': y})\n",
    "    y_cat = pd.get_dummies(df['col1']).to_numpy()\n",
    "    \n",
    "    print(\"proccessing\")\n",
    "    mag_encoded = mag[:, :1024, :]\n",
    "    \n",
    "    from keras.layers import Conv2D, Conv1D, BatchNormalization, ReLU, MaxPooling1D, UpSampling1D, Dense, Softmax, Reshape, Flatten, Input, Dropout\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "               Input((1024, 9)),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Conv1D(filters=10, kernel_size=5, activation='tanh', padding=\"same\"),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size = 2),\n",
    "                Flatten(),\n",
    "                Dense(512, activation='relu'),\n",
    "                Dropout(0.6),\n",
    "                BatchNormalization(),\n",
    "        \n",
    "                Dense(512, activation='relu'),\n",
    "                Dropout(0.6),\n",
    "                BatchNormalization(),\n",
    "        \n",
    "                Dense(512, activation='relu'),\n",
    "                Dropout(0.6),\n",
    "                BatchNormalization(),\n",
    "        \n",
    "                Dense(8, activation='softmax'),\n",
    "            ])\n",
    "#     model = tf.keras.Sequential([\n",
    "#             Input((64, 16)),\n",
    "#             Flatten(),\n",
    "#             Dense(256, activation='tanh'),\n",
    "#             Dense(256, activation='sigmoid'),\n",
    "#             Dense(256, activation='relu'),\n",
    "#             Dense(8, activation='softmax'),\n",
    "#         ])\n",
    "    \n",
    "    def scheduler(epoch):\n",
    "        if epoch % 5 == 4:\n",
    "            model.save(\"model.keras\")\n",
    "        return 0.001\n",
    "        if epoch < 30:\n",
    "            return 0.001\n",
    "        elif epoch < 100:\n",
    "            return 0.0005\n",
    "        else:\n",
    "            return 0.0001\n",
    "    print(mag_encoded.shape, y_cat.shape)\n",
    "    model.compile(Adam(), 'categorical_crossentropy', 'categorical_accuracy')\n",
    "    model.fit(mag_encoded, y_cat, epochs=100, \n",
    "            callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)], validation_split=0.2, verbose=2)\n",
    "\n",
    "run_proc(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5183057c",
   "metadata": {
    "cellId": "jn48slpxa9qmypgap7bsnq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 16:26:34.905193: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-16 16:26:35.334946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: GRID A100X-1-5C MIG 1g.5gb, pci bus id: 0000:8c:00.0, compute capability: 8.0\n",
      "2022-09-16 16:26:36.054330: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-16 16:26:36.743816: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-09-16 16:26:37.933607: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting proc\n",
      "processing x\n",
      "  autoencoder\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "processing y\n",
      "load model\n",
      "confusion matrix\n",
      "(7996, 8)\n",
      "[[0.11667339 0.14175113 0.11960492 0.12665664 0.12259732 0.12679233\n",
      "  0.13212846 0.11379588]\n",
      " [0.14226915 0.12479449 0.08894964 0.17497246 0.10102151 0.1280257\n",
      "  0.1292968  0.11067025]\n",
      " [0.09513927 0.13377663 0.10467512 0.09310499 0.0640965  0.1157955\n",
      "  0.12832224 0.26508972]]\n",
      "[[  0 230  34 514  61  30   0 130]\n",
      " [  1 345  98 122 162 130   0 141]\n",
      " [  0 169 390  48 177 118   0  98]\n",
      " [  1 151  10 560  14  53   0 210]\n",
      " [  1 285 153  83 347  79   0  52]\n",
      " [  0 237  91 163  70 300   0 139]\n",
      " [  0 269  84 225  61 108   0 253]\n",
      " [  0 138  68 174  32  47   0 540]]\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "def test():\n",
    "    import numpy as np\n",
    "    print(\"processing x\")\n",
    "    mag_ang = nnorm(get_x_stft(np.load(\"x.npy\")))\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "    \n",
    "    print(\"  autoencoder\")\n",
    "    autoencoder = getAutoencoder()()\n",
    "    autoencoder.load()\n",
    "    autoencoder.encoder.compile()\n",
    "    mag_encoded = autoencoder.encoder.predict(mag[:, :1024, :])\n",
    "    \n",
    "    print(\"processing y\")\n",
    "    import pandas as pd\n",
    "    y = np.load(\"y.npy\")\n",
    "    df = pd.DataFrame(data={'col1': y})\n",
    "    y_cat = pd.get_dummies(df['col1']).to_numpy()\n",
    "    \n",
    "    print(\"load model\")\n",
    "    from keras.models import load_model\n",
    "    model = load_model(\"model.keras\")\n",
    "    \n",
    "    print(\"confusion matrix\")\n",
    "    y_pred = model.predict(mag_encoded)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(y_pred.shape)\n",
    "    print(y_pred[:3])\n",
    "    print(confusion_matrix(y_cat.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "\n",
    "run_proc(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9fbc2",
   "metadata": {
    "cellId": "gk320owbjeom8tznu6aqdd"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d558158",
   "metadata": {
    "cellId": "dtqs2r61u2wwqqdkyi8omm"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "#!g2.mig\n",
    "def run():\n",
    "    import numpy as np\n",
    "    print(\"loading autoencoder\")\n",
    "    autoencoder = getAutoencoder()()\n",
    "    autoencoder.load()\n",
    "    autoencoder.encoder.compile()\n",
    "    print(\"reading and calculating stft\")\n",
    "    mag_ang = nnorm(get_x_stft(np.load(\"x.npy\")))\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "    \n",
    "    print(\"preparing y\")\n",
    "    import pandas as pd\n",
    "    y = np.load(\"y.npy\")\n",
    "    df = pd.DataFrame(data={'col1': y})\n",
    "    y_cat = pd.get_dummies(df['col1']).to_numpy()\n",
    "    \n",
    "    print(\"proccessing\")\n",
    "    mag_encoded = autoencoder.encoder.predict(mag[:, :1024, :])\n",
    "    print(mag_encoded.shape)\n",
    "    \n",
    "    from keras.layers import Conv2D, Conv1D, BatchNormalization, ReLU, MaxPooling1D, UpSampling1D, Dense, Softmax, Reshape, Flatten, Input, Dropout\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "                Input((64, 16)),\n",
    "                Flatten(),\n",
    "                Dense(512, activation='tanh'),\n",
    "                Dropout(0.8),\n",
    "                Dense(512, activation='sigmoid'),\n",
    "                Dropout(0.8),\n",
    "                Dense(512, activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(8, activation='softmax'),\n",
    "            ])\n",
    "#     model = tf.keras.Sequential([\n",
    "#             Input((64, 16)),\n",
    "#             Flatten(),\n",
    "#             Dense(256, activation='tanh'),\n",
    "#             Dense(256, activation='sigmoid'),\n",
    "#             Dense(256, activation='relu'),\n",
    "#             Dense(8, activation='softmax'),\n",
    "#         ])\n",
    "    \n",
    "    def scheduler(epoch):\n",
    "        if epoch % 5 == 4:\n",
    "            model.save(\"model.keras\")\n",
    "        return 0.001\n",
    "        if epoch < 30:\n",
    "            return 0.001\n",
    "        elif epoch < 100:\n",
    "            return 0.0005\n",
    "        else:\n",
    "            return 0.0001\n",
    "    print(mag_encoded.shape, y_cat.shape)\n",
    "    model.compile(Adam(), 'categorical_crossentropy', 'categorical_accuracy')\n",
    "    model.fit(mag_encoded, y_cat, epochs=100, \n",
    "            callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)], validation_split=0.2, verbose=2)\n",
    "\n",
    "run_proc(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b852dc1",
   "metadata": {
    "cellId": "uobmumg9vsfipxx9kmdai"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "def test():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y = np.load(\"y.npy\")\n",
    "    df = pd.DataFrame(data={'col1': y})\n",
    "    y_cat = pd.get_dummies(df['col1']).to_numpy()\n",
    "    return y_cat.sum(axis=0)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "976a7254",
   "metadata": {
    "cellId": "2012exnl55s0g7q0habel3o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "import numpy as np\n",
    "a = np.array([[[1, 100], [2, 200], [2, 300], [4, 123], [5, 1234]], \n",
    "              [[5, 12345], [6, 51235], [7, 152], [8, 51235], [123, 42134253]]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c69769e",
   "metadata": {
    "cellId": "g4gn2616r6qudvyeb2vv8"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-96767db7a5b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "np.concatenate((a[:, :3, :], a[:, 3:4, :]), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2820e902",
   "metadata": {
    "cellId": "ajan73dsqvgsa950mb585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a76b38",
   "metadata": {
    "cellId": "i2hejzn7dls7ny7k9f7l3"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8c480",
   "metadata": {
    "cellId": "z1o8u0zcqy71tqtt7ctib"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149fbe5",
   "metadata": {
    "cellId": "egxyoaads7myre4c8hpn8"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb162f34",
   "metadata": {
    "cellId": "fzqi34geytga7onnf8c4ei"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3189222",
   "metadata": {
    "cellId": "4e73d01s493j01bqmbel4q"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238ce1e",
   "metadata": {
    "cellId": "z3brnke1u0jqux9z03wyzk"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "x_stft[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27152dec",
   "metadata": {
    "cellId": "84gpoalbisb2bvfvwyv7zg"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "np.sum((aaa -bbb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce90c1",
   "metadata": {
    "cellId": "o8ga8htcc7ukqgoyt1v1b"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e04af6",
   "metadata": {
    "cellId": "7jpfoaf31faq38hxqnpz3"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9618c7",
   "metadata": {
    "cellId": "4lv5fk2uuo5qvphotig33"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "mag_ang[0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30d4dc",
   "metadata": {
    "cellId": "2sc1xq40uqlxcx1njxuk1d"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "mag_ang[0:, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c781830",
   "metadata": {
    "cellId": "swgzqsi7ewj45by0fsq1ky"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "def test():\n",
    "    from keras.models import load_model\n",
    "    import numpy as np\n",
    "\n",
    "    mag_ang = nnorm(get_x_stft(np.load(\"x.npy\")))\n",
    "    mag, ang = np.dsplit(mag_ang[0:1, :, :], 2)\n",
    "    ma = np.dstack((mag[:, :, 2], ang[:, :, 2]))\n",
    "    model = load_model('model.keras')\n",
    "#     m1, a1 = np.dsplit(model.predict(ma), 2)\n",
    "    m2, a2 = np.dsplit(ma, 2)\n",
    "    m1, a1 = model.predict(m2), a2\n",
    "\n",
    "    np.save(\"m1,a1,m2,a2\", [m1.reshape(1025),a1.reshape(1025),m2.reshape(1025),a2.reshape(1025)])\n",
    "\n",
    "def run():\n",
    "    run_proc(test)\n",
    "    m1,a1,m2,a2 = np.load(\"m1,a1,m2,a2.npy\", allow_pickle=True)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(m1[:100])\n",
    "    plt.plot(m2[:100])\n",
    "    plt.show()\n",
    "    plt.plot(a1[:100])\n",
    "    plt.plot(a2[:100])\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4daa8",
   "metadata": {
    "cellId": "ppkb8ib3vdbl0vnoniaoce"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22224a0",
   "metadata": {
    "cellId": "fy5p6pxgjx4qb4hg6wa9q"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55ec5306",
   "metadata": {
    "cellId": "smh4odam9fk8pg7o4ned8i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 19:43:01.756117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-15 19:43:02.210690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: GRID A100X-1-5C MIG 1g.5gb, pci bus id: 0000:8c:00.0, compute capability: 8.0\n",
      "2022-09-15 19:43:09.671023: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-15 19:43:10.540951: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-09-15 19:43:11.658420: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting proc\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "(1, 1025, 18)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n",
      "(1, 1025, 1)\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "\n",
    "\n",
    "def test():\n",
    "    global x_stft_pred\n",
    "    import numpy as np\n",
    "    model = getAutoencoder()()\n",
    "    model.load()\n",
    "    \n",
    "    x_stft_pred = []\n",
    "    mag_ang = nnorm(get_x_stft(np.load(\"x.npy\")))[1:2, :, :]\n",
    "    print(mag_ang.shape)\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "    for i in range(9):\n",
    "    #     print(x_stft[0, :, i].shape)\n",
    "#         a = model.predict(np.dstack([  mag[0, :, i], ang[0, :, i]    ]))\n",
    "        m1 = np.array([   mag[0, :, i:i+1]   ])\n",
    "        a = np.dstack([       model_predict_mag(model, m1), ang[0, :, i]    ])\n",
    "        print(denorm(a).shape)\n",
    "        x_stft_pred.append(denorm(a).reshape(1025))\n",
    "\n",
    "    x_stft_pred = np.array(x_stft_pred)\n",
    "    x_stft_pred = np.swapaxes(x_stft_pred, 0, 1)\n",
    "    \n",
    "    np.save(\"x_stft_pred\", x_stft_pred)\n",
    "\n",
    "run_proc(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc3cb1b7",
   "metadata": {
    "cellId": "k37z762pwoi4wcufs5pai6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 20:06:53.001103: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-15 20:06:53.522106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: GRID A100X-1-5C MIG 1g.5gb, pci bus id: 0000:8c:00.0, compute capability: 8.0\n",
      "2022-09-15 20:07:00.892888: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-15 20:07:01.792924: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-09-15 20:07:02.925166: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting proc\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "(5, 1025, 18)\n",
      "(5, 1025, 9) (5, 1025, 9)\n",
      "(5, 1025, 18)\n",
      "(5, 1025, 9)\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "\n",
    "\n",
    "def test():\n",
    "    global x_stft_pred\n",
    "    import numpy as np\n",
    "    model = getAutoencoder()()\n",
    "    model.load()\n",
    "    \n",
    "    x_stft_pred = []\n",
    "    mag_ang = nnorm(get_x_stft(np.load(\"x.npy\")))[:10, :, :]\n",
    "    print(mag_ang.shape)\n",
    "    mag, ang = np.dsplit(mag_ang, 2)\n",
    "    \n",
    "    m1 = mag[:, :, :]\n",
    "    \n",
    "    mag_pred = model_predict_mag(model, m1)\n",
    "    ang_pred = ang[:, :, :]\n",
    "    \n",
    "    print(mag_pred.shape, ang_pred.shape)\n",
    "    \n",
    "    a = np.dstack((mag_pred, ang_pred))\n",
    "    print(a.shape)\n",
    "    x_stft_pred = denorm(a)\n",
    "    print(x_stft_pred.shape)\n",
    "#     x_stft_pred = .reshape(1025)\n",
    "\n",
    "#     x_stft_pred = np.array(x_stft_pred)\n",
    "#     x_stft_pred = np.swapaxes(x_stft_pred, 0, 1)\n",
    "    \n",
    "    np.save(\"x_stft_pred\", x_stft_pred)\n",
    "\n",
    "run_proc(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5f9e406",
   "metadata": {
    "cellId": "iqf3vbvmhdm5g6nhcfn8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import numpy as np\n",
    "SAMPLE_RATE = 4096\n",
    "\n",
    "ipd.Audio(data=librosa.istft(librosa.stft(np.load(\"x.npy\")[4])), rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95418d34",
   "metadata": {
    "cellId": "hazkiqj4haa979yz6da0si"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "\n",
    "ipd.Audio(data=librosa.istft(np.load(\"x_stft_pred.npy\")[4]), rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5da968",
   "metadata": {
    "cellId": "vzdi4tbgt4kt2niyx2xyv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e09757",
   "metadata": {
    "cellId": "ulzfdmggfw8i8rm9fx156d"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "plt.plot(np.abs(x_stft[0, :, 0]))\n",
    "plt.show()\n",
    "plt.plot(np.abs(x_stft_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b880f",
   "metadata": {
    "cellId": "tlun7d363xmuk91ti7jva"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(librosa.istft(librosa.stft(x[0])))\n",
    "plt.plot(librosa.istft(x_stft_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7da2f",
   "metadata": {
    "cellId": "9e7xludwltrmws2clfz2xk"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "librosa.istft(x_stft[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66e2f5",
   "metadata": {
    "cellId": "b4qpk2v6rca8ubc3570k5a"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "librosa.istft(x_stft[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273652e",
   "metadata": {
    "cellId": "d97nlyfaaeugd0rmkgrwk"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "librosa.istft(x_stft_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b0afc",
   "metadata": {
    "cellId": "z10o9z45et8q0yg82wrrqj"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "x_stft[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bff82",
   "metadata": {
    "cellId": "ii0tg1m9l2aqryybh61zd"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "x_stft_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361400d",
   "metadata": {
    "cellId": "61xtlz5m0e6d4mpm7kdpw"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc239672",
   "metadata": {
    "cellId": "u59spjsk9mo4h06fs1tf9p"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7191de",
   "metadata": {
    "cellId": "k54ijgmntlm43bokkcqa"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "notebookId": "51db425e-814b-445f-82e5-c6dcc80a3081",
  "notebookPath": "good_autoencoder.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
